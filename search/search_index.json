{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"RydbergGPT","text":"<p>A large language model (LLM) for Rydberg atom array physics. Manuscript available on arXiv.</p>"},{"location":"#architecture","title":"Architecture","text":""},{"location":"#rydberg-system","title":"Rydberg System","text":"\\[ \\hat{H}_{\\mathrm{Rydberg}} =  \\sum_{i &lt; j}^{N} \\frac{C_6}{\\lVert \\mathbf{r}_i - \\mathbf{r}_j \\rVert} \\hat{n}_i \\hat{n}_j - \\delta \\sum_{i}^{N} \\hat{n}_i - \\frac{\\Omega}{2} \\sum_{i}^{N} \\hat{\\sigma}_i^{(x)}, \\] \\[ C_6 = \\Omega \\left( \\frac{R_b}{a} \\right)^6, \\quad V_{ij} = \\frac{a^6}{\\lVert \\mathbf{r}_i - \\mathbf{r}_j \\rVert^6} \\] <ul> <li>\\(N = L \\times L =\\) number of atoms/qubits</li> <li>\\(i, j =\\) qubit index</li> <li>\\(V_{ij} =\\) blockade interaction between qubits \\(i\\) and \\(j\\)</li> <li>\\(a =\\) Lattice spacing</li> <li>\\(R_b =\\) Rydberg blockade radius</li> <li>\\(\\mathbf{r}_i =\\) the position of qubit \\(i\\)</li> <li>\\(\\hat{n}_i =\\) number operator at qubit \\(i\\)</li> <li>\\(\\delta =\\) detuning at qubit \\(i\\)</li> <li>\\(\\Omega =\\) Rabi frequency at qubit \\(i\\)</li> <li>\\(\\beta =\\) Inverse temperature of system</li> </ul>"},{"location":"#transformer","title":"Transformer","text":"<p>Vanilla transformer architecture taken from Attention is All You Need.</p> <p></p> <ul> <li>\\(\\mathbf{x} =\\) experimental settings</li> <li>\\(\\sigma_i =\\) one-hot encoding of measured qubit \\(i\\)</li> <li>\\(p_{\\theta}(\\sigma_i | \\sigma_{&lt; i}) =\\) neural network conditional probability distribution of qubit \\(i\\)</li> </ul> <p>The transformer encoder represents the Rydberg Hamiltonian with a sequence.  The transformer decoder represents the corresponding ground state wavefunction.</p>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>We sincerely thank the authors of the following very helpful codebases we used when building this repository :</p> <ul> <li>Transformer tutorials:<ul> <li>Annotated Transformer</li> <li>Illustrated Transformer</li> </ul> </li> <li>Transformer quantum state:<ul> <li>Predicting Properties of Quantum Systems with Conditional Generative Models</li> <li>Transformer Quantum State</li> </ul> </li> </ul>"},{"location":"#references","title":"References","text":"<pre><code>@inproceedings{46201,\ntitle   = {Attention is All You Need},\nauthor  = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},\nyear    = {2017},\nURL = {https://arxiv.org/pdf/1706.03762.pdf}\n}\n</code></pre>"},{"location":"data/","title":"Data","text":""},{"location":"data/#rydberg-system","title":"Rydberg System","text":"\\[ \\hat{H}_{\\mathrm{Rydberg}} =  \\sum_{i &lt; j}^{N} \\frac{C_6}{\\lVert \\mathbf{r}_i - \\mathbf{r}_j \\rVert} \\hat{n}_i \\hat{n}_j - \\delta \\sum_{i}^{N} \\hat{n}_i - \\frac{\\Omega}{2} \\sum_{i}^{N} \\hat{\\sigma}_i^{(x)}, \\] \\[ C_6 = \\Omega \\left( \\frac{R_b}{a} \\right)^6, \\quad V_{ij} = \\frac{a^6}{\\lVert \\mathbf{r}_i - \\mathbf{r}_j \\rVert^6} \\] <ul> <li>\\(N = L \\times L =\\) number of atoms/qubits</li> <li>\\(i, j =\\) qubit index</li> <li>\\(V_{ij} =\\) blockade interaction between qubits \\(i\\) and \\(j\\)</li> <li>\\(a =\\) Lattice spacing</li> <li>\\(R_b =\\) Rydberg blockade radius</li> <li>\\(\\mathbf{r}_i =\\) the position of qubit \\(i\\)</li> <li>\\(\\hat{n}_i =\\) number operator at qubit \\(i\\)</li> <li>\\(\\delta =\\) detuning at qubit \\(i\\)</li> <li>\\(\\Omega =\\) Rabi frequency at qubit \\(i\\)</li> </ul>"},{"location":"data/#dataset","title":"Dataset","text":"<p>Consider setting \\(\\Omega = 1\\) and varying the other Hamiltonian parameters independently :</p> <ul> <li>\\(L = [5, 6, 11, 12, 15, 16]\\)</li> <li>\\(\\delta / \\Omega = [-0.36, -0.13, 0.93, 1.05, 1.17, 1.29, 1.52, 1.76, 2.94, 3.17]\\)</li> <li>\\(R_b / a = [1.05, 1.15, 1.3]\\)</li> <li>\\(\\beta \\Omega = [0.5, 1, 2, 4, 8, 16, 32, 48, 64]\\)</li> </ul> <p>Data available on Pennylane Datasets</p>"},{"location":"get_started/","title":"Get Started","text":""},{"location":"get_started/#installation","title":"Installation","text":"<p>Clone the repository using the following command: <pre><code>git clone https://github.com/PIQuIL/RydbergGPT\n</code></pre> Install with pip : <pre><code>cd RydbergGPT\npip install .\n</code></pre></p>"},{"location":"get_started/#usage","title":"Usage","text":""},{"location":"get_started/#tutorials","title":"Tutorials","text":"<p>You find tutorials for using RydbergGPT in the <code>examples/</code> folder.</p>"},{"location":"get_started/#configuration","title":"Configuration","text":"<p>The<code>config.yaml</code> is used to define the hyperparameters for: - Model architecture - Training settings - Data loading - Others</p>"},{"location":"get_started/#training","title":"Training","text":"<p>To train RydbergGPT locally, execute the <code>train.py</code> with:  <pre><code>python train.py --config_name=config_small.yaml\n</code></pre></p>"},{"location":"reference/data/","title":"Data","text":""},{"location":"reference/data/#rydberggpt.data","title":"<code>rydberggpt.data</code>","text":""},{"location":"reference/data/#rydberggpt.data.dataclasses","title":"<code>dataclasses</code>","text":""},{"location":"reference/data/#rydberggpt.data.dataclasses.BaseGraph","title":"<code>BaseGraph</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ABC</code></p> <p>A base dataclass representing a graph configuration.</p> Source code in <code>src/rydberggpt/data/dataclasses.py</code> <pre><code>@dataclass\nclass BaseGraph(ABC):\n    \"\"\"A base dataclass representing a graph configuration.\"\"\"\n\n    num_atoms: int\n    graph_name: str\n    Rb: float\n    delta: float\n    omega: float\n    beta: float\n</code></pre>"},{"location":"reference/data/#rydberggpt.data.dataclasses.Batch","title":"<code>Batch</code>  <code>dataclass</code>","text":"<p>A dataclass representing a batch of graphs</p> Source code in <code>src/rydberggpt/data/dataclasses.py</code> <pre><code>@dataclass\nclass Batch:\n    \"\"\"A dataclass representing a batch of graphs\"\"\"\n\n    graph: Data\n    m_onehot: torch.Tensor\n</code></pre>"},{"location":"reference/data/#rydberggpt.data.dataclasses.GridGraph","title":"<code>GridGraph</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseGraph</code></p> <p>A dataclass representing the configuration of a grid graph</p> Source code in <code>src/rydberggpt/data/dataclasses.py</code> <pre><code>@dataclass\nclass GridGraph(BaseGraph):\n    \"\"\"A dataclass representing the configuration of a grid graph\"\"\"\n\n    n_rows: int\n    n_cols: int\n</code></pre>"},{"location":"reference/data/#rydberggpt.data.dataclasses.custom_collate","title":"<code>custom_collate(batch: List[Batch]) -&gt; Batch</code>","text":"<p>Custom collate function to handle Batch objects when creating a DataLoader.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>List[Batch]</code> <p>A list of Batch objects to be collated.</p> required <p>Returns:</p> Type Description <code>Batch</code> <p>A single Batch object containing the collated data.</p> Source code in <code>src/rydberggpt/data/dataclasses.py</code> <pre><code>def custom_collate(batch: List[Batch]) -&gt; Batch:\n    \"\"\"\n    Custom collate function to handle Batch objects when creating a DataLoader.\n\n    Args:\n        batch (List[Batch]): A list of Batch objects to be collated.\n\n    Returns:\n        (Batch): A single Batch object containing the collated data.\n    \"\"\"\n\n    graph_batch = PyGBatch.from_data_list([b.graph for b in batch])\n\n    # NOTE: The graphs, and measurement data are not of the same size. To ensure\n    # a padded tensor suitable for the neural network, we use the to_dense_batch function. This ensures that our\n    # data is padded with zeros.\n    # see: https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/utils/to_dense_batch.html\n\n    m_onehot = to_dense_batch(\n        torch.cat([b.m_onehot for b in batch], axis=-2),\n        batch=graph_batch.batch,\n    )[0].to(torch.float32)\n\n    return Batch(graph=graph_batch, m_onehot=m_onehot)\n</code></pre>"},{"location":"reference/data/#rydberggpt.data.graph_structures","title":"<code>graph_structures</code>","text":""},{"location":"reference/data/#rydberggpt.data.graph_structures.generate_grid_graph","title":"<code>generate_grid_graph(n_rows: int, n_cols: int) -&gt; nx.Graph</code>","text":"<p>Generates a fully connected grid graph with weights based on the reciprocal of Euclidean distance. Coordinates is in units of lattice constant a.</p> <p>Parameters:</p> Name Type Description Default <code>n_rows</code> <code>int</code> <p>The number of rows in the grid.</p> required <code>n_cols</code> <code>int</code> <p>The number of columns in the grid.</p> required <p>Returns:</p> Type Description <code>Graph</code> <p>The generated grid graph with node positions and edge weights.</p> Source code in <code>src/rydberggpt/data/graph_structures.py</code> <pre><code>def generate_grid_graph(n_rows: int, n_cols: int) -&gt; nx.Graph:\n    \"\"\"\n    Generates a fully connected grid graph with weights based on the reciprocal of Euclidean distance. Coordinates is in units of lattice constant a.\n\n    Args:\n        n_rows (int): The number of rows in the grid.\n        n_cols (int): The number of columns in the grid.\n\n    Returns:\n        (nx.Graph): The generated grid graph with node positions and edge weights.\n    \"\"\"\n\n    # Create an empty graph\n    graph = nx.Graph()\n\n    # Add nodes with positions as attributes\n    for i in range(n_rows):\n        for j in range(n_cols):\n            node_id = i * n_cols + j\n            graph.add_node(node_id, pos=(i, j))\n\n    # Add fully connected edges with weights as the reciprocal of Euclidean distance\n    for node1 in graph.nodes:\n        pos1 = np.array(graph.nodes[node1][\"pos\"])\n        for node2 in graph.nodes:\n            if node1 != node2:\n                pos2 = np.array(graph.nodes[node2][\"pos\"])\n                interaction_strength = np.linalg.norm(pos1 - pos2) ** (-6)\n                graph.add_edge(node1, node2, weight=interaction_strength)\n\n    return graph\n</code></pre>"},{"location":"reference/data/#rydberggpt.data.graph_structures.get_graph","title":"<code>get_graph(config: BaseGraph) -&gt; nx.Graph</code>","text":"<p>Generates a graph based on the given configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>BaseGraph</code> <p>The graph configuration, an instance of a subclass of the BaseGraph dataclass.</p> required <p>Returns:</p> Type Description <code>Graph</code> <p>The generated graph based on the configuration.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the graph name provided in the configuration is not implemented.</p> Source code in <code>src/rydberggpt/data/graph_structures.py</code> <pre><code>def get_graph(config: BaseGraph) -&gt; nx.Graph:\n    \"\"\"\n    Generates a graph based on the given configuration.\n\n    Args:\n        config (BaseGraph): The graph configuration, an instance of a subclass of the BaseGraph dataclass.\n\n    Returns:\n        (nx.Graph): The generated graph based on the configuration.\n\n    Raises:\n        NotImplementedError: If the graph name provided in the configuration is not implemented.\n    \"\"\"\n    if config.graph_name == \"grid_graph\":\n        graph = generate_grid_graph(config.n_rows, config.n_cols)\n\n    else:\n        raise NotImplementedError(f\"Graph name {config.graph_name} not implemented.\")\n\n    return graph\n</code></pre>"},{"location":"reference/data/#rydberggpt.data.rydberg_dataset","title":"<code>rydberg_dataset</code>","text":""},{"location":"reference/data/#rydberggpt.data.rydberg_dataset.build_datapipes","title":"<code>build_datapipes(root_dir: str, batch_size: int, buffer_size: int)</code>","text":"<p>Builds a data pipeline for processing files from a specified directory.</p> <p>This function initializes a FileLister to list files from the specified directory and its subdirectories. It then demultiplexes the files into three separate data pipes for processing configuration, dataset, and graph files respectively. The configuration and graph files are opened, parsed as JSON, and processed using a custom selection function. The data pipes are then zipped together, shuffled, filtered, and buffered into batches using a custom collate function.</p> <p>Parameters:</p> Name Type Description Default <code>root_dir</code> <code>str</code> <p>The root directory from which to list files.</p> required <code>batch_size</code> <code>int</code> <p>The number of samples per batch.</p> required <code>buffer_size</code> <code>int</code> <p>The buffer size to use when buffering data into batches.</p> required <p>Returns:</p> Type Description <code>IterDataPipe</code> <p>The final data pipe containing batches of processed data.</p> Source code in <code>src/rydberggpt/data/rydberg_dataset.py</code> <pre><code>def build_datapipes(root_dir: str, batch_size: int, buffer_size: int):\n    \"\"\"\n    Builds a data pipeline for processing files from a specified directory.\n\n    This function initializes a FileLister to list files from the specified\n    directory and its subdirectories. It then demultiplexes the files into\n    three separate data pipes for processing configuration, dataset, and\n    graph files respectively. The configuration and graph files are opened,\n    parsed as JSON, and processed using a custom selection function.\n    The data pipes are then zipped together, shuffled, filtered, and buffered\n    into batches using a custom collate function.\n\n    Args:\n        root_dir (str): The root directory from which to list files.\n        batch_size (int): The number of samples per batch.\n        buffer_size (int): The buffer size to use when buffering data into batches.\n\n    Returns:\n        (IterDataPipe): The final data pipe containing batches of processed data.\n    \"\"\"\n    file_lister = FileLister([root_dir], recursive=True)\n    config_dp, dataset_dp, graph_dp = file_lister.demux(\n        3,\n        classify_file_fn,\n        drop_none=True,\n        buffer_size=-1,\n    )\n    config_dp = config_dp.open_files().parse_json_files()\n    graph_dp = graph_dp.open_files().parse_json_files()\n    datapipe = config_dp.zip(dataset_dp).zip(graph_dp).map(map_fn)\n    datapipe = datapipe.shuffle()\n    datapipe = Buffer(source_datapipe=datapipe, buffer_size=buffer_size)\n    datapipe = datapipe.batch(batch_size).collate(custom_collate).sharding_filter()\n\n    return datapipe\n</code></pre>"},{"location":"reference/data/#rydberggpt.data.utils_graph","title":"<code>utils_graph</code>","text":""},{"location":"reference/data/#rydberggpt.data.utils_graph.batch_pyg_data","title":"<code>batch_pyg_data(data_list: List[Data]) -&gt; Data</code>","text":"<p>Batch a list of PyTorch Geometric Data objects into a single Data object.</p> <p>Parameters:</p> Name Type Description Default <code>data_list</code> <code>List[Data]</code> <p>List of PyTorch Geometric Data objects.</p> required <p>Returns:</p> Type Description <code>Data</code> <p>A single batched Data object containing all input Data objects.</p> Source code in <code>src/rydberggpt/data/utils_graph.py</code> <pre><code>def batch_pyg_data(data_list: List[Data]) -&gt; Data:\n    \"\"\"\n    Batch a list of PyTorch Geometric Data objects into a single Data object.\n\n    Args:\n        data_list: List of PyTorch Geometric Data objects.\n\n    Returns:\n        (Data): A single batched Data object containing all input Data objects.\n    \"\"\"\n    batched_data = PyGBatch.from_data_list(data_list)\n    return batched_data\n</code></pre>"},{"location":"reference/data/#rydberggpt.data.utils_graph.dict_to_graph","title":"<code>dict_to_graph(graph_dict: Dict) -&gt; nx.Graph</code>","text":"<p>Create a NetworkX graph from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>graph_dict</code> <code>Dict</code> <p>Dictionary representing a NetworkX graph.</p> required <p>Returns:</p> Type Description <code>Graph</code> <p>NetworkX graph object.</p> Source code in <code>src/rydberggpt/data/utils_graph.py</code> <pre><code>def dict_to_graph(graph_dict: Dict) -&gt; nx.Graph:\n    \"\"\"\n    Create a NetworkX graph from a dictionary.\n\n    Args:\n        graph_dict: Dictionary representing a NetworkX graph.\n\n    Returns:\n        (nx.Graph): NetworkX graph object.\n    \"\"\"\n    graph = nx.node_link_graph(graph_dict)\n    return graph\n</code></pre>"},{"location":"reference/data/#rydberggpt.data.utils_graph.graph_to_dict","title":"<code>graph_to_dict(graph: nx.Graph) -&gt; Dict</code>","text":"<p>Convert a NetworkX graph to a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>Graph</code> <p>NetworkX graph object.</p> required <p>Returns:</p> Type Description <code>Dict</code> <p>A dictionary representing the NetworkX graph.</p> Source code in <code>src/rydberggpt/data/utils_graph.py</code> <pre><code>def graph_to_dict(graph: nx.Graph) -&gt; Dict:\n    \"\"\"\n    Convert a NetworkX graph to a dictionary.\n\n    Args:\n        graph: NetworkX graph object.\n\n    Returns:\n        (Dict): A dictionary representing the NetworkX graph.\n    \"\"\"\n    graph_dict = nx.node_link_data(graph)\n    return graph_dict\n</code></pre>"},{"location":"reference/data/#rydberggpt.data.utils_graph.networkx_to_pyg_data","title":"<code>networkx_to_pyg_data(graph: nx.Graph, node_features: torch.Tensor) -&gt; Data</code>","text":"<p>Convert a NetworkX graph to a PyTorch Geometric Data object.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>Graph</code> <p>NetworkX graph object.</p> required <p>Returns:</p> Type Description <code>Data</code> <p>A PyTorch Geometric Data object representing the input graph.</p> Source code in <code>src/rydberggpt/data/utils_graph.py</code> <pre><code>def networkx_to_pyg_data(graph: nx.Graph, node_features: torch.Tensor) -&gt; Data:\n    \"\"\"\n    Convert a NetworkX graph to a PyTorch Geometric Data object.\n\n    Args:\n        graph: NetworkX graph object.\n\n    Returns:\n        (Data): A PyTorch Geometric Data object representing the input graph.\n    \"\"\"\n\n    x = node_features.repeat(len(graph.nodes()), 1)\n\n    # Convert the edge list to a PyTorch Geometric edge_index tensor\n    edge_index = torch.tensor(list(graph.edges), dtype=torch.long).t().contiguous()\n\n    # Get edge weights from the graph\n    edge_weight = torch.tensor(\n        list(nx.get_edge_attributes(graph, \"weight\").values()), dtype=torch.float\n    )\n\n    # Create a Data object\n    data = Data(x=x, edge_index=edge_index, edge_attr=edge_weight)\n\n    return data\n</code></pre>"},{"location":"reference/data/#rydberggpt.data.utils_graph.pyg_graph_data","title":"<code>pyg_graph_data(config, graph_data)</code>","text":"<p>Convert a graph in node-link format to a PyG Data object.</p> <p>Parameters:</p> Name Type Description Default <code>graph_data</code> <code>Dict</code> <p>The graph in node-link format.</p> required <code>config_data</code> <code>Dict</code> <p>The configuration data for the graph.</p> required <p>Returns:</p> Type Description <code>Data</code> <p>The graph as a PyG Data object.</p> Source code in <code>src/rydberggpt/data/utils_graph.py</code> <pre><code>def pyg_graph_data(config, graph_data):\n    \"\"\"\n    Convert a graph in node-link format to a PyG Data object.\n\n    Args:\n        graph_data (Dict): The graph in node-link format.\n        config_data (Dict): The configuration data for the graph.\n\n    Returns:\n        (Data): The graph as a PyG Data object.\n\n    \"\"\"\n    node_features = torch.tensor(\n        [\n            config[\"delta\"],\n            config[\"omega\"],\n            config[\"beta\"],\n            config[\"Rb\"],\n        ],\n        dtype=torch.float32,\n    )\n    graph_nx = nx.node_link_graph(graph_data)\n    pyg_graph = networkx_to_pyg_data(graph_nx, node_features)\n    return pyg_graph\n</code></pre>"},{"location":"reference/data/#rydberggpt.data.utils_graph.read_graph_from_json","title":"<code>read_graph_from_json(file_path: str) -&gt; Dict</code>","text":"<p>Read a JSON file and convert it to a dictionary representing a NetworkX graph.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Path to the JSON file to read.</p> required <p>Returns:</p> Type Description <code>Dict</code> <p>A dictionary representing a NetworkX graph.</p> Source code in <code>src/rydberggpt/data/utils_graph.py</code> <pre><code>def read_graph_from_json(file_path: str) -&gt; Dict:\n    \"\"\"\n    Read a JSON file and convert it to a dictionary representing a NetworkX graph.\n\n    Args:\n        file_path: Path to the JSON file to read.\n\n    Returns:\n        (Dict): A dictionary representing a NetworkX graph.\n    \"\"\"\n    with open(file_path, \"r\") as f:\n        graph_dict = json.load(f)\n    return graph_dict\n</code></pre>"},{"location":"reference/data/#rydberggpt.data.utils_graph.save_graph_to_json","title":"<code>save_graph_to_json(graph_dict: Dict, file_path: str) -&gt; None</code>","text":"<p>Save a dictionary representing a NetworkX graph to a JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>graph_dict</code> <code>Dict</code> <p>Dictionary representing a NetworkX graph.</p> required <code>file_path</code> <code>str</code> <p>Path to the JSON file to save.</p> required Source code in <code>src/rydberggpt/data/utils_graph.py</code> <pre><code>def save_graph_to_json(graph_dict: Dict, file_path: str) -&gt; None:\n    \"\"\"\n    Save a dictionary representing a NetworkX graph to a JSON file.\n\n    Args:\n        graph_dict: Dictionary representing a NetworkX graph.\n        file_path: Path to the JSON file to save.\n    \"\"\"\n    with open(file_path, \"w\") as f:\n        json.dump(graph_dict, f)\n</code></pre>"},{"location":"reference/observables/","title":"Observables","text":""},{"location":"reference/observables/#rydberggpt.observables","title":"<code>rydberggpt.observables</code>","text":""},{"location":"reference/observables/#rydberggpt.observables.rydberg_energy","title":"<code>rydberg_energy</code>","text":""},{"location":"reference/observables/#rydberggpt.observables.rydberg_energy.get_rydberg_energy","title":"<code>get_rydberg_energy(model: RydbergEncoderDecoder, samples: torch.Tensor, cond: torch.Tensor, device: torch.device, undo_sample_path=None, undo_sample_path_args=None) -&gt; torch.Tensor</code>","text":"<p>Calculates energy of the model based on the Hamiltonian defined by cond (graph).</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>RydbergEncoderDecoder</code> <p>Model to estimate energy on.</p> required <code>samples</code> <code>Tensor</code> <p>Samples drawn from model based on cond.</p> required <code>cond</code> <code>Tensor</code> <p>A tensor containing the input condition.</p> required <code>device</code> <code>str</code> <p>The device on which to allocate the tensors. Defaults to \"cpu\".</p> required <code>undo_sample_path</code> <code>Tensor</code> <p>Map that undoes the sample path of the model to match the labelling of in the graph.</p> <code>None</code> <code>undo_sample_path_args</code> <code>tuple</code> <p>Additional arguments for undo_sample_path.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor containing the estimated energy of each sample alongside its decomposition into terms.</p> Source code in <code>src/rydberggpt/observables/rydberg_energy.py</code> <pre><code>@torch.no_grad()\ndef get_rydberg_energy(\n    model: RydbergEncoderDecoder,\n    samples: torch.Tensor,  # dtype=torch.int64\n    cond: torch.Tensor,  # dtype=torch.float32\n    device: torch.device,\n    undo_sample_path=None,\n    undo_sample_path_args=None,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Calculates energy of the model based on the Hamiltonian defined by cond (graph).\n\n    Args:\n        model (RydbergEncoderDecoder): Model to estimate energy on.\n        samples (torch.Tensor): Samples drawn from model based on cond.\n        cond (torch.Tensor): A tensor containing the input condition.\n        device (str, optional): The device on which to allocate the tensors. Defaults to \"cpu\".\n        undo_sample_path (torch.Tensor): Map that undoes the sample path of the model to match the labelling of in the graph.\n        undo_sample_path_args (tuple): Additional arguments for undo_sample_path.\n\n    Returns:\n        (torch.Tensor): A tensor containing the estimated energy of each sample alongside its decomposition into terms.\n    \"\"\"\n\n    model = model.to(device)\n    samples = samples.to(device)\n    cond = cond.to(device)\n\n    delta = cond.x[:, 0]  # Detuning coeffs\n    omega = cond.x[0, 1]  # Rabi frequency\n    # beta = cond.x[0, 2]  # Inverse temperature\n    Rb = cond.x[0, 3]  # Rydberg Blockade radius\n\n    # Estimate interaction/Rydberg blockade term\n    if undo_sample_path is not None:\n        unpathed_samples = undo_sample_path(samples, *undo_sample_path_args)\n    else:\n        unpathed_samples = samples\n\n    interaction = (\n        (\n            unpathed_samples[..., cond.edge_index].prod(dim=-2)\n            * cond.edge_attr[None, ...]\n        ).sum(dim=-1)\n        * Rb**6\n        * omega\n    )\n\n    detuning = (delta * unpathed_samples).sum(1)  # sum over sequence length\n\n    x_magnetization = get_x_magnetization(model, samples, cond, device)\n\n    offdiag_energy = 0.5 * omega * x_magnetization\n    diag_energy = interaction - detuning\n    energy = diag_energy - offdiag_energy\n\n    return torch.stack(\n        [\n            energy,\n            interaction,\n            detuning,\n            diag_energy,\n            offdiag_energy,\n        ]\n    ).T\n</code></pre>"},{"location":"reference/observables/#rydberggpt.observables.rydberg_energy.get_staggered_magnetization","title":"<code>get_staggered_magnetization(samples: torch.Tensor, Lx: int, Ly: int, device: torch.device, undo_sample_path=None, undo_sample_path_args=None)</code>","text":"<p>Calculates staggered magnetization of the model.</p> <p>Parameters:</p> Name Type Description Default <code>samples</code> <code>Tensor</code> <p>Samples drawn from model.</p> required <code>Lx</code> <code>int</code> <p>Linear size in the x dimension</p> required <code>Ly</code> <code>int</code> <p>Linear size in the y dimension</p> required <code>device</code> <code>str</code> <p>The device on which to allocate the tensors. Defaults to \"cpu\".</p> required <code>undo_sample_path</code> <code>Tensor</code> <p>Map that undoes the sample path of the model to match the labelling of in the graph.</p> <code>None</code> <code>undo_sample_path_args</code> <code>tuple</code> <p>Additional arguments for undo_sample_path.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor containing the estimated staggered magnetization of each sample.</p> Source code in <code>src/rydberggpt/observables/rydberg_energy.py</code> <pre><code>@torch.no_grad()\ndef get_staggered_magnetization(\n    samples: torch.Tensor,\n    Lx: int,\n    Ly: int,\n    device: torch.device,\n    undo_sample_path=None,\n    undo_sample_path_args=None,\n):\n    \"\"\"\n    Calculates staggered magnetization of the model.\n\n    Args:\n        samples (torch.Tensor): Samples drawn from model.\n        Lx (int): Linear size in the x dimension\n        Ly (int): Linear size in the y dimension\n        device (str, optional): The device on which to allocate the tensors. Defaults to \"cpu\".\n        undo_sample_path (torch.Tensor): Map that undoes the sample path of the model to match the labelling of in the graph.\n        undo_sample_path_args (tuple): Additional arguments for undo_sample_path.\n\n    Returns:\n        (torch.Tensor): A tensor containing the estimated staggered magnetization of each sample.\n    \"\"\"\n\n    if undo_sample_path is not None:\n        unpathed_samples = undo_sample_path(samples, *undo_sample_path_args)\n    else:\n        unpathed_samples = samples\n\n    unpathed_samples = unpathed_samples.reshape(-1, Ly, Lx)\n\n    unpathed_sigmas = 2 * unpathed_samples - 1\n\n    idcs = np.indices((Ly, Lx))\n    checkerboard = 2 * (idcs.sum(0) % 2) - 1\n    checkerboard = torch.from_numpy(checkerboard).to(device=device)\n\n    staggered_magnetization = torch.abs((checkerboard * unpathed_sigmas).mean((-1, -2)))\n\n    return staggered_magnetization\n</code></pre>"},{"location":"reference/observables/#rydberggpt.observables.rydberg_energy.get_x_magnetization","title":"<code>get_x_magnetization(model: RydbergEncoderDecoder, samples: torch.Tensor, cond: torch.Tensor, device: torch.device)</code>","text":"<p>Calculates x magnetization of the model.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>RydbergEncoderDecoder</code> <p>Model to estimate energy on.</p> required <code>samples</code> <code>Tensor</code> <p>Samples drawn from model based on cond.</p> required <code>cond</code> <code>Tensor</code> <p>A tensor containing the input condition.</p> required <code>device</code> <code>str</code> <p>The device on which to allocate the tensors. Defaults to \"cpu\".</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor containing the estimated x magnetization of each sample.</p> Source code in <code>src/rydberggpt/observables/rydberg_energy.py</code> <pre><code>@torch.no_grad()\ndef get_x_magnetization(\n    model: RydbergEncoderDecoder,\n    samples: torch.Tensor,  # dtype=torch.int64\n    cond: torch.Tensor,  # dtype=torch.float32\n    device: torch.device,\n):\n    \"\"\"\n    Calculates x magnetization of the model.\n\n    Args:\n        model (RydbergEncoderDecoder): Model to estimate energy on.\n        samples (torch.Tensor): Samples drawn from model based on cond.\n        cond (torch.Tensor): A tensor containing the input condition.\n        device (str, optional): The device on which to allocate the tensors. Defaults to \"cpu\".\n\n    Returns:\n        (torch.Tensor): A tensor containing the estimated x magnetization of each sample.\n    \"\"\"\n\n    model = model.to(device)\n    samples = samples.to(device)\n    cond = cond.to(device)\n\n    # Create all possible states achievable by a single spin flip\n    flipped = (samples[:, None, :] + torch.eye(samples.shape[-1])[None, ...]) % 2\n    flipped = flipped.reshape(-1, samples.shape[-1])\n\n    # Get propabilities of sampled states and the single spin flipped states\n    sample_log_probs = model.get_log_probs(to_one_hot(samples, 2), cond)\n    flipped_log_probs = model.get_log_probs(to_one_hot(flipped, 2), cond)\n    flipped_log_probs = flipped_log_probs.reshape(-1, samples.shape[-1])\n\n    # Calculate ratio of the wavefunction for the sampled and flipped states\n    log_psi_ratio = 0.5 * (flipped_log_probs - sample_log_probs[:, None])\n    psi_ratio = torch.exp(log_psi_ratio)\n\n    x_magnetization = psi_ratio.sum(-1)\n    return x_magnetization\n</code></pre>"},{"location":"reference/training/","title":"Training","text":""},{"location":"reference/training/#rydberggpt.training","title":"<code>rydberggpt.training</code>","text":""},{"location":"reference/training/#rydberggpt.training.callbacks","title":"<code>callbacks</code>","text":""},{"location":"reference/training/#rydberggpt.training.callbacks.module_info_callback","title":"<code>module_info_callback</code>","text":""},{"location":"reference/training/#rydberggpt.training.callbacks.module_info_callback.ModelInfoCallback","title":"<code>ModelInfoCallback</code>","text":"<p>               Bases: <code>Callback</code></p> <p>A custom PyTorch Lightning callback that logs model information at the start of training.</p> <p>This callback extracts and logs information about the model's structure, total parameters, and total trainable parameters at the beginning of the training process. The information is saved as a YAML file in the logger's log directory.</p> Source code in <code>src/rydberggpt/training/callbacks/module_info_callback.py</code> <pre><code>class ModelInfoCallback(Callback):\n    \"\"\"\n    A custom PyTorch Lightning callback that logs model information at the start of training.\n\n    This callback extracts and logs information about the model's structure, total parameters, and\n    total trainable parameters at the beginning of the training process. The information is saved\n    as a YAML file in the logger's log directory.\n    \"\"\"\n\n    def on_train_start(self, trainer, pl_module) -&gt; None:\n        \"\"\"\n        Run the callback at the beginning of training.\n\n        Args:\n            trainer (pytorch_lightning.Trainer): The PyTorch Lightning trainer instance.\n            pl_module (pytorch_lightning.LightningModule): The PyTorch Lightning module instance.\n        \"\"\"\n        # This will run at the beginning of training\n        log_path = trainer.logger.log_dir\n\n        summary = ModelSummary(pl_module, max_depth=1)\n        total_parameters = summary.total_parameters\n        total_trainable_parameters = summary.trainable_parameters\n\n        summary_dict = extract_model_info(pl_module.model)\n        summary_dict[\"total_parameters\"] = total_parameters\n        summary_dict[\"total_trainable_parameters\"] = total_trainable_parameters\n\n        # Save the summary dictionary to a YAML file\n        with open(f\"{log_path}/model_info.yaml\", \"w\") as file:\n            yaml.dump(summary_dict, file)\n</code></pre>"},{"location":"reference/training/#rydberggpt.training.callbacks.module_info_callback.ModelInfoCallback.on_train_start","title":"<code>on_train_start(trainer, pl_module) -&gt; None</code>","text":"<p>Run the callback at the beginning of training.</p> <p>Parameters:</p> Name Type Description Default <code>trainer</code> <code>Trainer</code> <p>The PyTorch Lightning trainer instance.</p> required <code>pl_module</code> <code>LightningModule</code> <p>The PyTorch Lightning module instance.</p> required Source code in <code>src/rydberggpt/training/callbacks/module_info_callback.py</code> <pre><code>def on_train_start(self, trainer, pl_module) -&gt; None:\n    \"\"\"\n    Run the callback at the beginning of training.\n\n    Args:\n        trainer (pytorch_lightning.Trainer): The PyTorch Lightning trainer instance.\n        pl_module (pytorch_lightning.LightningModule): The PyTorch Lightning module instance.\n    \"\"\"\n    # This will run at the beginning of training\n    log_path = trainer.logger.log_dir\n\n    summary = ModelSummary(pl_module, max_depth=1)\n    total_parameters = summary.total_parameters\n    total_trainable_parameters = summary.trainable_parameters\n\n    summary_dict = extract_model_info(pl_module.model)\n    summary_dict[\"total_parameters\"] = total_parameters\n    summary_dict[\"total_trainable_parameters\"] = total_trainable_parameters\n\n    # Save the summary dictionary to a YAML file\n    with open(f\"{log_path}/model_info.yaml\", \"w\") as file:\n        yaml.dump(summary_dict, file)\n</code></pre>"},{"location":"reference/training/#rydberggpt.training.logger","title":"<code>logger</code>","text":""},{"location":"reference/training/#rydberggpt.training.logger.setup_logger","title":"<code>setup_logger(log_path)</code>","text":"<p>Set up the logger to write logs to a file and the console.</p> Source code in <code>src/rydberggpt/training/logger.py</code> <pre><code>def setup_logger(log_path):\n    \"\"\"\n    Set up the logger to write logs to a file and the console.\n    \"\"\"\n    # Ensure the log_path exists\n    if not os.path.exists(log_path):\n        os.makedirs(log_path)\n\n    logger = logging.getLogger()\n    logger.setLevel(logging.INFO)\n\n    # Console Handler\n    ch = logging.StreamHandler()\n    ch.setLevel(logging.INFO)\n    formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n    ch.setFormatter(formatter)\n    logger.addHandler(ch)\n\n    # File Handler\n    fh = logging.FileHandler(os.path.join(log_path, \"training.log\"))\n    fh.setLevel(logging.INFO)\n    fh.setFormatter(formatter)\n    logger.addHandler(fh)\n\n    return logger\n</code></pre>"},{"location":"reference/training/#rydberggpt.training.loss","title":"<code>loss</code>","text":""},{"location":"reference/training/#rydberggpt.training.loss.NLLLoss","title":"<code>NLLLoss</code>","text":"<p>               Bases: <code>LightningModule</code></p> <p>This class implements the Negative Log Likelihood (NLL) loss function as a PyTorch Lightning module.</p> <p>The NLL loss measures the performance of a classification model where the prediction input is a probability distribution over classes. It is useful in training models for multi-class classification problems.</p> <p>The loss is calculated by taking the negative log of the probabilities predicted by the model for the true class labels.</p> <p>Methods:</p> Name Description <code>forward</code> <p>Computes the NLL loss based on the conditional log probabilities and the target values.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; nll_loss = NLLLoss()\n&gt;&gt;&gt; loss = nll_loss(cond_log_probs, tgt)\n</code></pre> Source code in <code>src/rydberggpt/training/loss.py</code> <pre><code>class NLLLoss(pl.LightningModule):\n    \"\"\"\n    This class implements the Negative Log Likelihood (NLL) loss function as a PyTorch Lightning module.\n\n    The NLL loss measures the performance of a classification model where the prediction input is a probability\n    distribution over classes. It is useful in training models for multi-class classification problems.\n\n    The loss is calculated by taking the negative log of the probabilities predicted by the model for the true class labels.\n\n    Methods:\n        forward:\n            Computes the NLL loss based on the conditional log probabilities and the target values.\n\n    Examples:\n        &gt;&gt;&gt; nll_loss = NLLLoss()\n        &gt;&gt;&gt; loss = nll_loss(cond_log_probs, tgt)\n    \"\"\"\n\n    def __init__(self):\n        super(NLLLoss, self).__init__()\n\n    def forward(self, cond_log_probs: Tensor, tgt: Tensor) -&gt; Tensor:\n        \"\"\"\n        Computes the NLL loss based on the conditional log probabilities and the target values.\n\n        Args:\n            cond_log_probs (Tensor): The conditional log probabilities predicted by the model.\n            tgt (Tensor): The target values.\n\n        Returns:\n            (Tensor): The computed NLL loss.\n        \"\"\"\n        num_atoms = tgt.shape[-2] - (tgt == 0.0).all(-1).sum(-1)\n        log_probs = (cond_log_probs * tgt).sum(dim=(-2, -1))\n        loss = -torch.mean(log_probs / num_atoms)\n        return loss\n</code></pre>"},{"location":"reference/training/#rydberggpt.training.loss.NLLLoss.forward","title":"<code>forward(cond_log_probs: Tensor, tgt: Tensor) -&gt; Tensor</code>","text":"<p>Computes the NLL loss based on the conditional log probabilities and the target values.</p> <p>Parameters:</p> Name Type Description Default <code>cond_log_probs</code> <code>Tensor</code> <p>The conditional log probabilities predicted by the model.</p> required <code>tgt</code> <code>Tensor</code> <p>The target values.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The computed NLL loss.</p> Source code in <code>src/rydberggpt/training/loss.py</code> <pre><code>def forward(self, cond_log_probs: Tensor, tgt: Tensor) -&gt; Tensor:\n    \"\"\"\n    Computes the NLL loss based on the conditional log probabilities and the target values.\n\n    Args:\n        cond_log_probs (Tensor): The conditional log probabilities predicted by the model.\n        tgt (Tensor): The target values.\n\n    Returns:\n        (Tensor): The computed NLL loss.\n    \"\"\"\n    num_atoms = tgt.shape[-2] - (tgt == 0.0).all(-1).sum(-1)\n    log_probs = (cond_log_probs * tgt).sum(dim=(-2, -1))\n    loss = -torch.mean(log_probs / num_atoms)\n    return loss\n</code></pre>"},{"location":"reference/training/#rydberggpt.training.train","title":"<code>train</code>","text":""},{"location":"reference/training/#rydberggpt.training.trainer","title":"<code>trainer</code>","text":""},{"location":"reference/training/#rydberggpt.training.trainer.RydbergGPTTrainer","title":"<code>RydbergGPTTrainer</code>","text":"<p>               Bases: <code>LightningModule</code></p> <p>A custom PyTorch Lightning module for training a Rydberg GPT model.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>The model to be trained.</p> required <code>config</code> <code>dataclass</code> <p>A dataclass containing the model's configuration parameters.</p> required <code>logger</code> <code>TensorBoardLogger</code> <p>A TensorBoard logger instance for logging training progress.</p> <code>None</code> <code>example_input_array</code> <code>tensor</code> <p>An example input tensor used for generating the model summary.</p> <code>None</code> Source code in <code>src/rydberggpt/training/trainer.py</code> <pre><code>class RydbergGPTTrainer(pl.LightningModule):\n    \"\"\"\n    A custom PyTorch Lightning module for training a Rydberg GPT model.\n\n    Args:\n        model (nn.Module): The model to be trained.\n        config (dataclass): A dataclass containing the model's configuration parameters.\n        logger (TensorBoardLogger): A TensorBoard logger instance for logging training progress.\n        example_input_array (torch.tensor, optional): An example input tensor used for\n            generating the model summary.\n    \"\"\"\n\n    def __init__(\n        self,\n        model: nn.Module,\n        config: dataclass,\n        logger: TensorBoardLogger = None,\n        example_input_array: torch.tensor = None,\n    ) -&gt; None:\n        super().__init__()\n        self.config = config\n        self.save_hyperparameters(asdict(config))\n        self.model = model\n        self.criterion = getattr(loss, self.config.criterion)()\n        self.example_input_array = example_input_array\n\n    def forward(self, m_onehot: torch.Tensor, cond: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Perform a forward pass through the model.\n\n        Args:\n            m_onehot (torch.Tensor): One-hot encoded measurements tensor.\n            cond (torch.Tensor): Conditioning tensor. # TODO prompt\n\n        Returns:\n            (torch.Tensor): Conditional log probabilities tensor.\n        \"\"\"\n        out = self.model.forward(m_onehot, cond)\n        cond_log_probs = self.model.generator(out)\n        return cond_log_probs\n\n    def training_step(self, batch: torch.Tensor, batch_idx: int) -&gt; torch.Tensor:\n        \"\"\"\n        Perform a single training step.\n\n        Args:\n            batch (pl.Batch): A batch of data during training.\n            batch_idx (int): The index of the current batch.\n\n        Returns:\n            (torch.Tensor): The training loss for the current batch.\n        \"\"\"\n        m_shifted_onehot = shift_inputs(batch.m_onehot)\n\n        cond_log_probs = self.forward(m_shifted_onehot, batch.graph)\n        loss = self.criterion(cond_log_probs, batch.m_onehot)\n        self.log(\"train_loss\", loss, sync_dist=True)\n        return loss\n\n    def configure_optimizers(self) -&gt; Dict[str, Union[optim.Optimizer, Dict]]:\n        \"\"\"\n        Configures the optimizer and learning rate scheduler for the RydbergGPTTrainer.\n\n        Returns:\n            (Dict[str, Union[optim.Optimizer, Dict]]): A dictionary containing the optimizer and lr_scheduler configurations.\n        \"\"\"\n        optimizer_class = getattr(optim, self.config.optimizer)\n        optimizer = optimizer_class(\n            self.model.parameters(), lr=self.config.learning_rate\n        )\n\n        # Add learning rate scheduler\n        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n            optimizer,\n            T_0=self.config.t_initial,  # initial number of epochs in a period\n            T_mult=self.config.t_mult,  # factor to increase the period length after each restart\n            eta_min=self.config.eta_min,  # minimum learning rate\n        )\n\n        # Return both the optimizer and the scheduler\n        return {\n            \"optimizer\": optimizer,\n            \"lr_scheduler\": {\n                \"scheduler\": scheduler,\n                \"interval\": \"epoch\",\n                \"monitor\": \"train_loss\",\n            },\n        }\n</code></pre>"},{"location":"reference/training/#rydberggpt.training.trainer.RydbergGPTTrainer.configure_optimizers","title":"<code>configure_optimizers() -&gt; Dict[str, Union[optim.Optimizer, Dict]]</code>","text":"<p>Configures the optimizer and learning rate scheduler for the RydbergGPTTrainer.</p> <p>Returns:</p> Type Description <code>Dict[str, Union[Optimizer, Dict]]</code> <p>A dictionary containing the optimizer and lr_scheduler configurations.</p> Source code in <code>src/rydberggpt/training/trainer.py</code> <pre><code>def configure_optimizers(self) -&gt; Dict[str, Union[optim.Optimizer, Dict]]:\n    \"\"\"\n    Configures the optimizer and learning rate scheduler for the RydbergGPTTrainer.\n\n    Returns:\n        (Dict[str, Union[optim.Optimizer, Dict]]): A dictionary containing the optimizer and lr_scheduler configurations.\n    \"\"\"\n    optimizer_class = getattr(optim, self.config.optimizer)\n    optimizer = optimizer_class(\n        self.model.parameters(), lr=self.config.learning_rate\n    )\n\n    # Add learning rate scheduler\n    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n        optimizer,\n        T_0=self.config.t_initial,  # initial number of epochs in a period\n        T_mult=self.config.t_mult,  # factor to increase the period length after each restart\n        eta_min=self.config.eta_min,  # minimum learning rate\n    )\n\n    # Return both the optimizer and the scheduler\n    return {\n        \"optimizer\": optimizer,\n        \"lr_scheduler\": {\n            \"scheduler\": scheduler,\n            \"interval\": \"epoch\",\n            \"monitor\": \"train_loss\",\n        },\n    }\n</code></pre>"},{"location":"reference/training/#rydberggpt.training.trainer.RydbergGPTTrainer.forward","title":"<code>forward(m_onehot: torch.Tensor, cond: torch.Tensor) -&gt; torch.Tensor</code>","text":"<p>Perform a forward pass through the model.</p> <p>Parameters:</p> Name Type Description Default <code>m_onehot</code> <code>Tensor</code> <p>One-hot encoded measurements tensor.</p> required <code>cond</code> <code>Tensor</code> <p>Conditioning tensor. # TODO prompt</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Conditional log probabilities tensor.</p> Source code in <code>src/rydberggpt/training/trainer.py</code> <pre><code>def forward(self, m_onehot: torch.Tensor, cond: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Perform a forward pass through the model.\n\n    Args:\n        m_onehot (torch.Tensor): One-hot encoded measurements tensor.\n        cond (torch.Tensor): Conditioning tensor. # TODO prompt\n\n    Returns:\n        (torch.Tensor): Conditional log probabilities tensor.\n    \"\"\"\n    out = self.model.forward(m_onehot, cond)\n    cond_log_probs = self.model.generator(out)\n    return cond_log_probs\n</code></pre>"},{"location":"reference/training/#rydberggpt.training.trainer.RydbergGPTTrainer.training_step","title":"<code>training_step(batch: torch.Tensor, batch_idx: int) -&gt; torch.Tensor</code>","text":"<p>Perform a single training step.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>Batch</code> <p>A batch of data during training.</p> required <code>batch_idx</code> <code>int</code> <p>The index of the current batch.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The training loss for the current batch.</p> Source code in <code>src/rydberggpt/training/trainer.py</code> <pre><code>def training_step(self, batch: torch.Tensor, batch_idx: int) -&gt; torch.Tensor:\n    \"\"\"\n    Perform a single training step.\n\n    Args:\n        batch (pl.Batch): A batch of data during training.\n        batch_idx (int): The index of the current batch.\n\n    Returns:\n        (torch.Tensor): The training loss for the current batch.\n    \"\"\"\n    m_shifted_onehot = shift_inputs(batch.m_onehot)\n\n    cond_log_probs = self.forward(m_shifted_onehot, batch.graph)\n    loss = self.criterion(cond_log_probs, batch.m_onehot)\n    self.log(\"train_loss\", loss, sync_dist=True)\n    return loss\n</code></pre>"},{"location":"reference/training/#rydberggpt.training.utils","title":"<code>utils</code>","text":""},{"location":"reference/training/#rydberggpt.training.utils.set_example_input_array","title":"<code>set_example_input_array(train_loader: DataLoader) -&gt; Tuple[Any, Any]</code>","text":"<p>Get an example input array from the train loader.</p> <p>Parameters:</p> Name Type Description Default <code>train_loader</code> <code>DataLoader</code> <p>The DataLoader instance for the training data.</p> required <p>Returns:</p> Type Description <code>Tuple[Any, Any]</code> <p>A tuple containing m_onehot and graph from the example batch.</p> Source code in <code>src/rydberggpt/training/utils.py</code> <pre><code>def set_example_input_array(train_loader: DataLoader) -&gt; Tuple[Any, Any]:\n    \"\"\"\n    Get an example input array from the train loader.\n\n    Args:\n        train_loader (DataLoader): The DataLoader instance for the training data.\n\n    Returns:\n        (Tuple[Any, Any]): A tuple containing m_onehot and graph from the example batch.\n    \"\"\"\n    logging.info(\"Setting example input array...\")\n    example_batch = next(iter(train_loader))\n    return example_batch.m_onehot, example_batch.graph\n</code></pre>"},{"location":"reference/utils/","title":"Utilities","text":""},{"location":"reference/utils/#rydberggpt.utils","title":"<code>rydberggpt.utils</code>","text":""},{"location":"reference/utils/#rydberggpt.utils.create_config_from_yaml","title":"<code>create_config_from_yaml(yaml_content: Dict) -&gt; dataclass</code>","text":"<p>Create a dataclass config object from the given YAML content.</p> <p>Parameters:</p> Name Type Description Default <code>yaml_content</code> <code>Dict</code> <p>A dictionary containing the YAML content.</p> required <p>Returns:</p> Type Description <code>dataclass</code> <p>A dataclass object representing the config.</p> Source code in <code>src/rydberggpt/utils.py</code> <pre><code>def create_config_from_yaml(yaml_content: Dict) -&gt; dataclass:\n    \"\"\"\n    Create a dataclass config object from the given YAML content.\n\n    Args:\n        yaml_content (Dict): A dictionary containing the YAML content.\n\n    Returns:\n        (dataclass): A dataclass object representing the config.\n    \"\"\"\n    flattened_config = flatten_yaml(yaml_content)\n    Config = create_dataclass_from_dict(\"Config\", flattened_config)\n    return Config(**flattened_config)\n</code></pre>"},{"location":"reference/utils/#rydberggpt.utils.create_dataclass_from_dict","title":"<code>create_dataclass_from_dict(name: str, data: Dict[str, Any]) -&gt; Type</code>","text":"<p>Create a dataclass from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the dataclass.</p> required <code>data</code> <code>Dict[str, Any]</code> <p>A dictionary containing the dataclass fields and their values.</p> required <p>Returns:</p> Type Description <code>Type</code> <p>A new dataclass with the specified name and fields.</p> Source code in <code>src/rydberggpt/utils.py</code> <pre><code>def create_dataclass_from_dict(name: str, data: Dict[str, Any]) -&gt; Type:\n    \"\"\"\n    Create a dataclass from a dictionary.\n\n    Args:\n        name (str): The name of the dataclass.\n        data (Dict[str, Any]): A dictionary containing the dataclass fields and their values.\n\n    Returns:\n        (Type): A new dataclass with the specified name and fields.\n    \"\"\"\n    fields = [(key, type(value)) for key, value in data.items()]\n    return make_dataclass(name, fields)\n</code></pre>"},{"location":"reference/utils/#rydberggpt.utils.flatten_yaml","title":"<code>flatten_yaml(yaml_config: Dict[str, Dict[str, Any]]) -&gt; Dict[str, Any]</code>","text":"<p>Flatten a nested YAML configuration dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>yaml_config</code> <code>Dict[str, Dict[str, Any]]</code> <p>A nested dictionary representing the YAML configuration.</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: A flattened dictionary with the nested structure removed.</p> Source code in <code>src/rydberggpt/utils.py</code> <pre><code>def flatten_yaml(yaml_config: Dict[str, Dict[str, Any]]) -&gt; Dict[str, Any]:\n    \"\"\"\n    Flatten a nested YAML configuration dictionary.\n\n    Args:\n        yaml_config (Dict[str, Dict[str, Any]]): A nested dictionary representing the YAML configuration.\n\n    Returns:\n        Dict[str, Any]: A flattened dictionary with the nested structure removed.\n    \"\"\"\n    flattened_config = {}\n    for section, section_values in yaml_config.items():\n        if isinstance(section_values, dict):\n            for key, value in section_values.items():\n                flattened_config[f\"{key}\"] = value\n        else:\n            flattened_config[section] = section_values\n    return flattened_config\n</code></pre>"},{"location":"reference/utils/#rydberggpt.utils.load_config_file","title":"<code>load_config_file(checkpoint_path: str, config_file: str = 'hparams.yaml') -&gt; str</code>","text":"<p>Load the configuration file associated with a given checkpoint.</p> <p>Parameters:</p> Name Type Description Default <code>checkpoint_path</code> <code>str</code> <p>The path to the checkpoint file.</p> required <code>config_file</code> <code>str</code> <p>The name of the configuration file, defaults to \"hparams.yaml\".</p> <code>'hparams.yaml'</code> <p>Returns:</p> Type Description <code>str</code> <p>The path to the configuration file.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the configuration file is not found in the specified directory.</p> Source code in <code>src/rydberggpt/utils.py</code> <pre><code>def load_config_file(checkpoint_path: str, config_file: str = \"hparams.yaml\") -&gt; str:\n    \"\"\"\n    Load the configuration file associated with a given checkpoint.\n\n    Args:\n        checkpoint_path (str): The path to the checkpoint file.\n        config_file (str, optional): The name of the configuration file, defaults to \"hparams.yaml\".\n\n    Returns:\n        (str): The path to the configuration file.\n\n    Raises:\n        FileNotFoundError: If the configuration file is not found in the specified directory.\n    \"\"\"\n    config_dir = os.path.dirname(os.path.dirname(checkpoint_path))\n\n    if not os.path.exists(os.path.join(config_dir, config_file)):\n        raise FileNotFoundError(f\"No config file found in {config_dir}\")\n\n    return os.path.join(config_dir, config_file)\n</code></pre>"},{"location":"reference/utils/#rydberggpt.utils.load_yaml_file","title":"<code>load_yaml_file(path: str, yaml_file_name: str) -&gt; Dict[str, Any]</code>","text":"<p>Load the content of a YAML file given its path and file name.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the directory containing the YAML file.</p> required <code>yaml_file_name</code> <code>str</code> <p>The name of the YAML file.</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: A dictionary containing the YAML content.</p> Source code in <code>src/rydberggpt/utils.py</code> <pre><code>def load_yaml_file(path: str, yaml_file_name: str) -&gt; Dict[str, Any]:\n    \"\"\"\n    Load the content of a YAML file given its path and file name.\n\n    Args:\n        path (str): The path to the directory containing the YAML file.\n        yaml_file_name (str): The name of the YAML file.\n\n    Returns:\n        Dict[str, Any]: A dictionary containing the YAML content.\n    \"\"\"\n    if not yaml_file_name.endswith(\".yaml\"):\n        yaml_file_name += \".yaml\"\n\n    yaml_path = os.path.join(path, yaml_file_name)\n    with open(yaml_path, \"r\") as file:\n        yaml_content = yaml.safe_load(file)\n    return yaml_content\n</code></pre>"},{"location":"reference/utils/#rydberggpt.utils.save_to_yaml","title":"<code>save_to_yaml(data: Dict[str, Any], filename: str) -&gt; None</code>","text":"<p>Save a dictionary to a file in YAML format.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[str, Any]</code> <p>The dictionary to be saved.</p> required <code>filename</code> <code>str</code> <p>The path to the file where the dictionary will be saved.</p> required Source code in <code>src/rydberggpt/utils.py</code> <pre><code>def save_to_yaml(data: Dict[str, Any], filename: str) -&gt; None:\n    \"\"\"\n    Save a dictionary to a file in YAML format.\n\n    Args:\n        data (Dict[str, Any]): The dictionary to be saved.\n        filename (str): The path to the file where the dictionary will be saved.\n    \"\"\"\n    with open(filename, \"w\") as file:\n        yaml.dump(data, file)\n</code></pre>"},{"location":"reference/utils/#rydberggpt.utils.shift_inputs","title":"<code>shift_inputs(tensor: torch.Tensor) -&gt; torch.Tensor</code>","text":"<p>Shifts the second dimension (S) of the input tensor by one position to the right and pads the beginning with zeros.</p> <p>Parameters:</p> Name Type Description Default <code>tensor</code> <code>Tensor</code> <p>The input tensor of shape [B, S, D].</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The resulting tensor after the shift and pad operation.</p> Source code in <code>src/rydberggpt/utils.py</code> <pre><code>def shift_inputs(tensor: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Shifts the second dimension (S) of the input tensor by one position to the right\n    and pads the beginning with zeros.\n\n    Args:\n        tensor (torch.Tensor): The input tensor of shape [B, S, D].\n\n    Returns:\n        (torch.Tensor): The resulting tensor after the shift and pad operation.\n    \"\"\"\n    B, _, D = tensor.size()\n    zero_padding = torch.zeros((B, 1, D), device=tensor.device, dtype=tensor.dtype)\n    shifted_tensor = torch.cat((zero_padding, tensor[:, :-1, :]), dim=1)\n    return shifted_tensor\n</code></pre>"},{"location":"reference/utils/#rydberggpt.utils.time_and_log","title":"<code>time_and_log(fn: Callable[..., Any]) -&gt; Callable[..., Any]</code>","text":"<p>Decorator function to measure the time taken by a function to execute and log it.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Callable[..., Any]</code> <p>The function to be wrapped.</p> required <p>Returns:</p> Type Description <code>Callable[..., Any]</code> <p>Callable[..., Any]: The wrapped function.</p> Usage <pre><code>@time_and_log\ndef my_function(arg1, arg2):\n    # function logic here\n</code></pre> Source code in <code>src/rydberggpt/utils.py</code> <pre><code>def time_and_log(fn: Callable[..., Any]) -&gt; Callable[..., Any]:\n    \"\"\"\n    Decorator function to measure the time taken by a function to execute and log it.\n\n    Args:\n        fn (Callable[..., Any]): The function to be wrapped.\n\n    Returns:\n        Callable[..., Any]: The wrapped function.\n\n    Usage:\n        ```py\n        @time_and_log\n        def my_function(arg1, arg2):\n            # function logic here\n        ```\n    \"\"\"\n\n    def wrapped(*args: Any, **kwargs: Any) -&gt; Any:\n        start_time = time.time()\n        result = fn(*args, **kwargs)\n        elapsed_time = time.time() - start_time\n\n        # Convert elapsed time to HH:MM:SS format\n        formatted_time = str(timedelta(seconds=elapsed_time))\n\n        logging.info(f\"{fn.__name__} took {formatted_time} to run.\")\n        return result\n\n    return wrapped\n</code></pre>"},{"location":"reference/utils/#rydberggpt.utils.to_one_hot","title":"<code>to_one_hot(data: Union[torch.Tensor, List[int], Tuple[int]], num_classes: int) -&gt; torch.Tensor</code>","text":"<p>Converts the input data into one-hot representation.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[Tensor, List[int], Tuple[int]]</code> <p>Input data to be converted into one-hot. It can be a 1D tensor, list or tuple of integers.</p> required <code>num_classes</code> <code>int</code> <p>Number of classes in the one-hot representation.</p> required <p>Returns:</p> Name Type Description <code>data</code> <code>Tensor</code> <p>The one-hot representation of the input data.</p> Source code in <code>src/rydberggpt/utils.py</code> <pre><code>def to_one_hot(\n    data: Union[torch.Tensor, List[int], Tuple[int]], num_classes: int\n) -&gt; torch.Tensor:\n    \"\"\"\n    Converts the input data into one-hot representation.\n\n    Args:\n        data: Input data to be converted into one-hot. It can be a 1D tensor, list or tuple of integers.\n        num_classes: Number of classes in the one-hot representation.\n\n    Returns:\n        data (torch.Tensor): The one-hot representation of the input data.\n    \"\"\"\n\n    if isinstance(data, (list, tuple)):\n        data = torch.tensor(data, dtype=torch.int64)\n    elif not isinstance(data, torch.Tensor):\n        raise TypeError(\"Input data must be a tensor, list or tuple of integers.\")\n\n    data = nn.functional.one_hot(data.long(), num_classes)\n\n    return data.to(torch.float)\n</code></pre>"},{"location":"reference/utils/#rydberggpt.utils_ckpt","title":"<code>rydberggpt.utils_ckpt</code>","text":""},{"location":"reference/utils/#rydberggpt.utils_ckpt.find_best_ckpt","title":"<code>find_best_ckpt(log_dir: str) -&gt; Optional[str]</code>","text":"<p>Find the best checkpoint file (with the lowest training loss) in the specified log directory.</p> <p>Parameters:</p> Name Type Description Default <code>log_dir</code> <code>str</code> <p>The path to the log directory containing the checkpoint files.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The path to the checkpoint file with the lowest training loss.</p> Source code in <code>src/rydberggpt/utils_ckpt.py</code> <pre><code>def find_best_ckpt(log_dir: str) -&gt; Optional[str]:\n    \"\"\"\n    Find the best checkpoint file (with the lowest training loss) in the specified log directory.\n\n    Args:\n        log_dir (str): The path to the log directory containing the checkpoint files.\n\n    Returns:\n        (str): The path to the checkpoint file with the lowest training loss.\n    \"\"\"\n    log_dir = os.path.join(log_dir, \"checkpoints\")\n    ckpt_files = [file for file in os.listdir(log_dir) if file.endswith(\".ckpt\")]\n\n    if not ckpt_files:\n        raise FileNotFoundError(f\"No checkpoint files found in {log_dir}\")\n\n    # Extract the training loss from the ckpt filenames\n    ckpt_losses = []\n    for file in ckpt_files:\n        match = re.search(r\"train_loss=(\\d+\\.\\d+)\", file)\n        if match:\n            ckpt_losses.append(float(match.group(1)))\n        else:\n            ckpt_losses.append(float(\"inf\"))\n\n    # Find the index of the ckpt with the lowest training loss\n    best_ckpt_index = ckpt_losses.index(min(ckpt_losses))\n    best_ckpt = ckpt_files[best_ckpt_index]\n\n    return os.path.join(log_dir, best_ckpt)\n</code></pre>"},{"location":"reference/utils/#rydberggpt.utils_ckpt.find_latest_ckpt","title":"<code>find_latest_ckpt(log_dir: str)</code>","text":"<p>Find the latest checkpoint file (based on modification time) in the specified log directory.</p> <p>Parameters:</p> Name Type Description Default <code>log_dir</code> <code>str</code> <p>The path to the log directory containing the checkpoint files.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The path to the latest checkpoint file.</p> Source code in <code>src/rydberggpt/utils_ckpt.py</code> <pre><code>def find_latest_ckpt(log_dir: str):\n    \"\"\"\n    Find the latest checkpoint file (based on modification time) in the specified log directory.\n\n    Args:\n        log_dir (str): The path to the log directory containing the checkpoint files.\n\n    Returns:\n        (str): The path to the latest checkpoint file.\n    \"\"\"\n    log_dir = os.path.join(log_dir, \"checkpoints\")\n    ckpt_files = [file for file in os.listdir(log_dir) if file.endswith(\".ckpt\")]\n\n    if not ckpt_files:\n        raise FileNotFoundError(f\"No checkpoint files found in {log_dir}\")\n\n    ckpt_files.sort(key=lambda x: os.path.getmtime(os.path.join(log_dir, x)))\n    latest_ckpt = ckpt_files[-1]\n    return os.path.join(log_dir, latest_ckpt)\n</code></pre>"},{"location":"reference/utils/#rydberggpt.utils_ckpt.get_ckpt_path","title":"<code>get_ckpt_path(from_ckpt: int, log_dir: str = 'logs/lightning_logs') -&gt; str</code>","text":"<p>Get the checkpoint path from a specified checkpoint version number.</p> <p>Parameters:</p> Name Type Description Default <code>from_ckpt</code> <code>int</code> <p>The version number of the checkpoint.</p> required <code>log_dir</code> <code>str</code> <p>The root directory where checkpoints are stored.                     Defaults to \"logs/lightning_logs\".</p> <code>'logs/lightning_logs'</code> <p>Returns:</p> Type Description <code>str</code> <p>The path to the specified checkpoint version directory.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If no checkpoint is found in the specified directory.</p> Source code in <code>src/rydberggpt/utils_ckpt.py</code> <pre><code>def get_ckpt_path(from_ckpt: int, log_dir: str = \"logs/lightning_logs\") -&gt; str:\n    \"\"\"\n    Get the checkpoint path from a specified checkpoint version number.\n\n    Args:\n        from_ckpt (int): The version number of the checkpoint.\n        log_dir (str, optional): The root directory where checkpoints are stored.\n                                Defaults to \"logs/lightning_logs\".\n\n    Returns:\n        (str): The path to the specified checkpoint version directory.\n\n    Raises:\n        FileNotFoundError: If no checkpoint is found in the specified directory.\n    \"\"\"\n    log_dir = os.path.join(log_dir, f\"version_{from_ckpt}\")\n\n    if log_dir is None:\n        raise FileNotFoundError(f\"No checkpoint found in {log_dir}\")\n\n    return log_dir\n</code></pre>"},{"location":"reference/utils/#rydberggpt.utils_ckpt.get_model_from_ckpt","title":"<code>get_model_from_ckpt(log_path: str, model: nn.Module, ckpt: str = 'best', trainer: pl.LightningModule = RydbergGPTTrainer) -&gt; nn.Module</code>","text":"<p>Load a model from a specified checkpoint file in the log directory.</p> <p>Parameters:</p> Name Type Description Default <code>log_path</code> <code>str</code> <p>The path to the log directory containing the checkpoint files.</p> required <code>model</code> <code>Module</code> <p>The model class to load.</p> required <code>ckpt</code> <code>str</code> <p>The checkpoint to load. Must be either \"best\" or \"latest\". Defaults to \"best\".</p> <code>'best'</code> <code>trainer</code> <code>LightningModule</code> <p>The trainer class to use for loading the model. Defaults to RydbergGPTTrainer.</p> <code>RydbergGPTTrainer</code> <p>Returns:</p> Type Description <code>Module</code> <p>The loaded model.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the value of ckpt is not \"best\" or \"latest\".</p> Source code in <code>src/rydberggpt/utils_ckpt.py</code> <pre><code>def get_model_from_ckpt(\n    log_path: str,\n    model: nn.Module,\n    ckpt: str = \"best\",\n    trainer: pl.LightningModule = RydbergGPTTrainer,\n) -&gt; nn.Module:\n    \"\"\"\n    Load a model from a specified checkpoint file in the log directory.\n\n    Args:\n        log_path (str): The path to the log directory containing the checkpoint files.\n        model (nn.Module): The model class to load.\n        ckpt (str, optional): The checkpoint to load. Must be either \"best\" or \"latest\". Defaults to \"best\".\n        trainer (pl.LightningModule, optional): The trainer class to use for loading the model. Defaults to RydbergGPTTrainer.\n\n    Returns:\n        (nn.Module): The loaded model.\n\n    Raises:\n        ValueError: If the value of ckpt is not \"best\" or \"latest\".\n    \"\"\"\n    if ckpt == \"best\":\n        ckpt_path = find_best_ckpt(log_path)\n    elif ckpt == \"last\":\n        ckpt_path = find_latest_ckpt(log_path)\n    else:\n        raise ValueError(f\"ckpt must be 'best' or 'latest', not {ckpt}\")\n\n    yaml_dict = load_yaml_file(log_path, \"hparams.yaml\")\n    config = create_config_from_yaml(yaml_dict)\n\n    rydberg_gpt_trainer = trainer.load_from_checkpoint(\n        ckpt_path,\n        model=model,\n        config=config,\n        logger=None,\n        example_input_array=None,\n    )\n    return rydberg_gpt_trainer.model\n</code></pre>"},{"location":"reference/models/","title":"Models","text":""},{"location":"reference/models/#rydberggpt.models.rydberg_decoder_wavefunction","title":"<code>rydberggpt.models.rydberg_decoder_wavefunction</code>","text":""},{"location":"reference/models/#rydberggpt.models.rydberg_decoder_wavefunction.RydbergDecoderWavefunction","title":"<code>RydbergDecoderWavefunction</code>","text":"<p>               Bases: <code>RydbergEncoderDecoder</code></p> Source code in <code>src/rydberggpt/models/rydberg_decoder_wavefunction.py</code> <pre><code>class RydbergDecoderWavefunction(RydbergEncoderDecoder):\n    def __init__(\n        self,\n        cond: Batch,\n        encoder: Encoder,\n        decoder: Decoder,\n        src_embed: nn.Module,\n        tgt_embed: nn.Module,\n        generator: Generator,\n        config=None,\n    ):\n        super().__init__(\n            encoder.eval(),\n            decoder,\n            src_embed.eval(),\n            tgt_embed,\n            generator,\n            config,\n        )\n\n        if hasattr(cond, \"num_graphs\") and cond.num_graphs &gt; 1:\n            raise ValueError(\"cond should represent a single Hamiltonian/graph\")\n\n        self.N = cond.num_nodes\n        self.cond = cond\n\n        for p in self.encoder.parameters():\n            p.requires_grad_(False)\n        for p in self.src_embed.parameters():\n            p.requires_grad_(False)\n\n        memory, batch_mask = self.encode(cond)\n        self.register_buffer(\"memory\", memory)\n        self.register_buffer(\"batch_mask\", batch_mask)\n        pass\n\n    def forward(self, tgt: torch.Tensor) -&gt; torch.Tensor:\n        memory = self.memory.repeat([*tgt.shape[:-2], 1, 1])\n        batch_mask = self.batch_mask.repeat([*tgt.shape[:-2], 1])\n\n        return self.decode(tgt, memory, batch_mask)\n\n    @classmethod\n    def from_rydberg_encoder_decoder(cls, cond: Batch, model: RydbergEncoderDecoder):\n        \"\"\"\n        Create RydbergDecoderWavefunction from a RydbergEncodeDecoder model and a Hamiltonian/graph.\n\n        Args:\n            cond (Batch): The Hamiltonian/graph.\n            model (RydbergEncoderDecoder): The model used to generate a RydbergDecoderWavefunction.\n\n        Returns:\n            (RydbergDecoderWavefunction): The wavefunction taken from a trained RydergEncoderDecoder model for the groundstate of the Hamiltonian/graph specified by cond.\n\n        \"\"\"\n        return cls(\n            cond,\n            model.encoder,\n            model.decoder,\n            model.src_embed,\n            model.tgt_embed,\n            model.generator,\n            model.config,\n        )\n\n    pass\n\n    def get_log_probs(self, x: torch.Tensor):\n        \"\"\"\n        Compute the log probabilities of a given input tensor.\n\n        Args:\n            x (torch.Tensor): The input tensor.\n\n        Returns:\n            (torch.Tensor): The log probabilities.\n        \"\"\"\n\n        assert (\n            len(x.shape) == 3 and x.shape[-1] == 2\n        ), \"The input must be one hot encoded\"\n\n        y = torch.zeros((x.shape[0], 1, x.shape[-1]))  # Initial token\n        y = y.to(x)  # Match dtype and device\n        y = torch.cat([y, x[:, :-1, :]], axis=-2)  # Append initial token to x\n\n        y = self.forward(y)  # EncoderDecoder forward pass\n        y = self.generator(y)  # Conditional log probs\n\n        y = torch.sum(torch.sum(y * x, axis=-1), axis=-1)  # Log prob of full x\n\n        return y\n\n    def get_samples(\n        self,\n        batch_size: int,\n        fmt_onehot: bool = True,\n        requires_grad: bool = False,\n        verbose: bool = True,\n    ):\n        \"\"\"\n        Generate samples using the forward pass and sampling from the conditional probabilities.\n        The samples can be returned either in one-hot encoding format or in label format,\n        according to the `fmt_onehot` argument.\n\n        Args:\n            batch_size (int): The number of samples to generate.\n            fmt_onehot (bool, optional): A flag to indicate whether to return the samples\n              in one-hot encoding format. If False, the samples are returned in label format. Defaults to True.\n            requires_grad (bool, optional): A flag to determine if grad is needed when sampling. Defaults to False,\n            verbose (bool, optional): A flag indicating whether to print sampling progress. Defaults to True,\n\n        Returns:\n            (torch.Tensor): A tensor containing the generated samples. The shape of the tensor is (batch_size, num_atoms, 2) for one-hot encoding format, and (batch_size, num_atoms) for label format. The samples are padded according to the number of nodes in each graph within `cond`.\n        \"\"\"\n        if verbose:\n            print(\"\")\n\n        num_atoms = self.N\n\n        m = torch.zeros(batch_size, 1, 2, device=self.device)\n\n        for i in range(num_atoms):\n            if verbose:\n                print(\"{:&lt;80}\".format(f\"\\rGenerating atom {i+1}/{num_atoms}\"), end=\"\")\n                sys.stdout.flush()\n\n            y = self.forward(m)  # EncoderDecoder forward pass\n            y = self.generator(y)  # Conditional log probs\n            y = y[:, -1, :]  # Next conditional log probs\n\n            if requires_grad:\n                y = F.gumbel_softmax(logits=y, tau=1, hard=True)[..., None, :]\n\n            else:\n                y = torch.distributions.Categorical(logits=y).sample(\n                    [\n                        1,\n                    ]\n                )  # Sample from next conditional log probs\n                y = y.reshape(y.shape[1], 1)  # Reshape\n                y = to_one_hot(y, 2)  # Convert from label to one hot encoding\n\n            m = torch.cat((m, y), dim=-2)  # Append next sample to tensor\n\n        if fmt_onehot:\n            m = m[:, 1:, :]  # Remove initial token\n        else:\n            m = m[:, 1:, -1]  # Remove initial token and put into label format\n\n        if verbose:\n            print(\"\")\n        return m\n\n    def get_x_magnetization(\n        self,\n        samples: torch.Tensor,  # dtype=torch.int64\n    ):\n        \"\"\"\n        Calculates x magnetization of the model.\n\n        Args:\n            samples (torch.Tensor): Samples drawn from model based on cond.\n\n        Returns:\n            (torch.Tensor): A tensor containing the estimated x magnetization of each sample.\n        \"\"\"\n\n        # Create all possible states achievable by a single spin flip\n        flipped = (samples[:, None, :] + torch.eye(samples.shape[-1])[None, ...]) % 2\n        flipped = flipped.reshape(-1, samples.shape[-1])\n\n        # Get propabilities of sampled states and the single spin flipped states\n        sample_log_probs = self.get_log_probs(to_one_hot(samples, 2))\n        flipped_log_probs = self.get_log_probs(to_one_hot(flipped, 2))\n        flipped_log_probs = flipped_log_probs.reshape(-1, samples.shape[-1])\n\n        # Calculate ratio of the wavefunction for the sampled and flipped states\n        log_psi_ratio = 0.5 * (flipped_log_probs - sample_log_probs[:, None])\n        psi_ratio = torch.exp(log_psi_ratio)\n\n        x_magnetization = psi_ratio.sum(-1)\n        return x_magnetization\n\n    def get_rydberg_energy(\n        self,\n        samples: torch.Tensor,  # dtype=torch.int64\n        undo_sample_path=None,\n        undo_sample_path_args=None,\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Calculates energy of the model based on the Hamiltonian defined by cond (graph).\n\n        Args:\n            samples (torch.Tensor): Samples drawn from model based on cond.\n           undo_sample_path (torch.Tensor): Map that undoes the sample path of the model to match the labelling of in the graph.\n           undo_sample_path_args (tuple): Additional arguments for undo_sample_path.\n\n        Returns:\n            (torch.Tensor): A tensor containing the estimated energy of each sample alongside its decomposition into terms.\n        \"\"\"\n\n        samples = samples\n        cond = self.cond\n\n        delta = cond.x[:, 0]  # Detuning coeffs\n        omega = cond.x[0, 1]  # Rabi frequency\n        # beta = cond.x[0, 2]  # Inverse Temperature\n        Rb = cond.x[0, 3]  # Rydberg Blockade radius\n\n        # Estimate interaction/Rydberg blockade term\n        if undo_sample_path is not None:\n            unpathed_samples = undo_sample_path(samples, *undo_sample_path_args)\n        else:\n            unpathed_samples = samples\n\n        interaction = (\n            (\n                unpathed_samples[..., cond.edge_index].prod(dim=-2)\n                * cond.edge_attr[None, ...]\n            ).sum(dim=-1)\n            * Rb**6\n            * omega\n        )\n\n        # Estimate detuning term\n        detuning = (delta * unpathed_samples).sum(-1)  # sum over sequence length\n\n        # Estimate sigma_x\n        x_magnetization = self.get_x_magnetization(samples)\n        offdiag_energy = 0.5 * omega * x_magnetization\n\n        # Diagonal part of energy\n        diag_energy = interaction - detuning\n\n        energy = diag_energy - offdiag_energy  # Energy estimate\n\n        return torch.stack(\n            [\n                energy,\n                interaction,\n                detuning,\n                diag_energy,\n                offdiag_energy,\n            ]\n        ).T\n\n    def variational_loss(\n        self, batch_size: int, undo_sample_path, undo_sample_path_args\n    ):\n        samples = self.get_samples(\n            batch_size=batch_size, fmt_onehot=False, requires_grad=True, verbose=False\n        )\n\n        N = self.N\n        omega = self.cond.x[0, 1]\n\n        energy = self.get_rydberg_energy(\n            samples=samples,\n            undo_sample_path=undo_sample_path,\n            undo_sample_path_args=undo_sample_path_args,\n        )[..., 0].mean() / (N * omega)\n\n        return energy\n</code></pre>"},{"location":"reference/models/#rydberggpt.models.rydberg_decoder_wavefunction.RydbergDecoderWavefunction.from_rydberg_encoder_decoder","title":"<code>from_rydberg_encoder_decoder(cond: Batch, model: RydbergEncoderDecoder)</code>  <code>classmethod</code>","text":"<p>Create RydbergDecoderWavefunction from a RydbergEncodeDecoder model and a Hamiltonian/graph.</p> <p>Parameters:</p> Name Type Description Default <code>cond</code> <code>Batch</code> <p>The Hamiltonian/graph.</p> required <code>model</code> <code>RydbergEncoderDecoder</code> <p>The model used to generate a RydbergDecoderWavefunction.</p> required <p>Returns:</p> Type Description <code>RydbergDecoderWavefunction</code> <p>The wavefunction taken from a trained RydergEncoderDecoder model for the groundstate of the Hamiltonian/graph specified by cond.</p> Source code in <code>src/rydberggpt/models/rydberg_decoder_wavefunction.py</code> <pre><code>@classmethod\ndef from_rydberg_encoder_decoder(cls, cond: Batch, model: RydbergEncoderDecoder):\n    \"\"\"\n    Create RydbergDecoderWavefunction from a RydbergEncodeDecoder model and a Hamiltonian/graph.\n\n    Args:\n        cond (Batch): The Hamiltonian/graph.\n        model (RydbergEncoderDecoder): The model used to generate a RydbergDecoderWavefunction.\n\n    Returns:\n        (RydbergDecoderWavefunction): The wavefunction taken from a trained RydergEncoderDecoder model for the groundstate of the Hamiltonian/graph specified by cond.\n\n    \"\"\"\n    return cls(\n        cond,\n        model.encoder,\n        model.decoder,\n        model.src_embed,\n        model.tgt_embed,\n        model.generator,\n        model.config,\n    )\n</code></pre>"},{"location":"reference/models/#rydberggpt.models.rydberg_decoder_wavefunction.RydbergDecoderWavefunction.get_log_probs","title":"<code>get_log_probs(x: torch.Tensor)</code>","text":"<p>Compute the log probabilities of a given input tensor.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>The input tensor.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The log probabilities.</p> Source code in <code>src/rydberggpt/models/rydberg_decoder_wavefunction.py</code> <pre><code>def get_log_probs(self, x: torch.Tensor):\n    \"\"\"\n    Compute the log probabilities of a given input tensor.\n\n    Args:\n        x (torch.Tensor): The input tensor.\n\n    Returns:\n        (torch.Tensor): The log probabilities.\n    \"\"\"\n\n    assert (\n        len(x.shape) == 3 and x.shape[-1] == 2\n    ), \"The input must be one hot encoded\"\n\n    y = torch.zeros((x.shape[0], 1, x.shape[-1]))  # Initial token\n    y = y.to(x)  # Match dtype and device\n    y = torch.cat([y, x[:, :-1, :]], axis=-2)  # Append initial token to x\n\n    y = self.forward(y)  # EncoderDecoder forward pass\n    y = self.generator(y)  # Conditional log probs\n\n    y = torch.sum(torch.sum(y * x, axis=-1), axis=-1)  # Log prob of full x\n\n    return y\n</code></pre>"},{"location":"reference/models/#rydberggpt.models.rydberg_decoder_wavefunction.RydbergDecoderWavefunction.get_rydberg_energy","title":"<code>get_rydberg_energy(samples: torch.Tensor, undo_sample_path=None, undo_sample_path_args=None) -&gt; torch.Tensor</code>","text":"<p>Calculates energy of the model based on the Hamiltonian defined by cond (graph).</p> <p>Parameters:</p> Name Type Description Default <code>samples</code> <code>Tensor</code> <p>Samples drawn from model based on cond.</p> required <p>undo_sample_path (torch.Tensor): Map that undoes the sample path of the model to match the labelling of in the graph.    undo_sample_path_args (tuple): Additional arguments for undo_sample_path.</p> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor containing the estimated energy of each sample alongside its decomposition into terms.</p> Source code in <code>src/rydberggpt/models/rydberg_decoder_wavefunction.py</code> <pre><code>def get_rydberg_energy(\n    self,\n    samples: torch.Tensor,  # dtype=torch.int64\n    undo_sample_path=None,\n    undo_sample_path_args=None,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Calculates energy of the model based on the Hamiltonian defined by cond (graph).\n\n    Args:\n        samples (torch.Tensor): Samples drawn from model based on cond.\n       undo_sample_path (torch.Tensor): Map that undoes the sample path of the model to match the labelling of in the graph.\n       undo_sample_path_args (tuple): Additional arguments for undo_sample_path.\n\n    Returns:\n        (torch.Tensor): A tensor containing the estimated energy of each sample alongside its decomposition into terms.\n    \"\"\"\n\n    samples = samples\n    cond = self.cond\n\n    delta = cond.x[:, 0]  # Detuning coeffs\n    omega = cond.x[0, 1]  # Rabi frequency\n    # beta = cond.x[0, 2]  # Inverse Temperature\n    Rb = cond.x[0, 3]  # Rydberg Blockade radius\n\n    # Estimate interaction/Rydberg blockade term\n    if undo_sample_path is not None:\n        unpathed_samples = undo_sample_path(samples, *undo_sample_path_args)\n    else:\n        unpathed_samples = samples\n\n    interaction = (\n        (\n            unpathed_samples[..., cond.edge_index].prod(dim=-2)\n            * cond.edge_attr[None, ...]\n        ).sum(dim=-1)\n        * Rb**6\n        * omega\n    )\n\n    # Estimate detuning term\n    detuning = (delta * unpathed_samples).sum(-1)  # sum over sequence length\n\n    # Estimate sigma_x\n    x_magnetization = self.get_x_magnetization(samples)\n    offdiag_energy = 0.5 * omega * x_magnetization\n\n    # Diagonal part of energy\n    diag_energy = interaction - detuning\n\n    energy = diag_energy - offdiag_energy  # Energy estimate\n\n    return torch.stack(\n        [\n            energy,\n            interaction,\n            detuning,\n            diag_energy,\n            offdiag_energy,\n        ]\n    ).T\n</code></pre>"},{"location":"reference/models/#rydberggpt.models.rydberg_decoder_wavefunction.RydbergDecoderWavefunction.get_samples","title":"<code>get_samples(batch_size: int, fmt_onehot: bool = True, requires_grad: bool = False, verbose: bool = True)</code>","text":"<p>Generate samples using the forward pass and sampling from the conditional probabilities. The samples can be returned either in one-hot encoding format or in label format, according to the <code>fmt_onehot</code> argument.</p> <p>Parameters:</p> Name Type Description Default <code>batch_size</code> <code>int</code> <p>The number of samples to generate.</p> required <code>fmt_onehot</code> <code>bool</code> <p>A flag to indicate whether to return the samples in one-hot encoding format. If False, the samples are returned in label format. Defaults to True.</p> <code>True</code> <code>requires_grad</code> <code>bool</code> <p>A flag to determine if grad is needed when sampling. Defaults to False,</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>A flag indicating whether to print sampling progress. Defaults to True,</p> <code>True</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor containing the generated samples. The shape of the tensor is (batch_size, num_atoms, 2) for one-hot encoding format, and (batch_size, num_atoms) for label format. The samples are padded according to the number of nodes in each graph within <code>cond</code>.</p> Source code in <code>src/rydberggpt/models/rydberg_decoder_wavefunction.py</code> <pre><code>def get_samples(\n    self,\n    batch_size: int,\n    fmt_onehot: bool = True,\n    requires_grad: bool = False,\n    verbose: bool = True,\n):\n    \"\"\"\n    Generate samples using the forward pass and sampling from the conditional probabilities.\n    The samples can be returned either in one-hot encoding format or in label format,\n    according to the `fmt_onehot` argument.\n\n    Args:\n        batch_size (int): The number of samples to generate.\n        fmt_onehot (bool, optional): A flag to indicate whether to return the samples\n          in one-hot encoding format. If False, the samples are returned in label format. Defaults to True.\n        requires_grad (bool, optional): A flag to determine if grad is needed when sampling. Defaults to False,\n        verbose (bool, optional): A flag indicating whether to print sampling progress. Defaults to True,\n\n    Returns:\n        (torch.Tensor): A tensor containing the generated samples. The shape of the tensor is (batch_size, num_atoms, 2) for one-hot encoding format, and (batch_size, num_atoms) for label format. The samples are padded according to the number of nodes in each graph within `cond`.\n    \"\"\"\n    if verbose:\n        print(\"\")\n\n    num_atoms = self.N\n\n    m = torch.zeros(batch_size, 1, 2, device=self.device)\n\n    for i in range(num_atoms):\n        if verbose:\n            print(\"{:&lt;80}\".format(f\"\\rGenerating atom {i+1}/{num_atoms}\"), end=\"\")\n            sys.stdout.flush()\n\n        y = self.forward(m)  # EncoderDecoder forward pass\n        y = self.generator(y)  # Conditional log probs\n        y = y[:, -1, :]  # Next conditional log probs\n\n        if requires_grad:\n            y = F.gumbel_softmax(logits=y, tau=1, hard=True)[..., None, :]\n\n        else:\n            y = torch.distributions.Categorical(logits=y).sample(\n                [\n                    1,\n                ]\n            )  # Sample from next conditional log probs\n            y = y.reshape(y.shape[1], 1)  # Reshape\n            y = to_one_hot(y, 2)  # Convert from label to one hot encoding\n\n        m = torch.cat((m, y), dim=-2)  # Append next sample to tensor\n\n    if fmt_onehot:\n        m = m[:, 1:, :]  # Remove initial token\n    else:\n        m = m[:, 1:, -1]  # Remove initial token and put into label format\n\n    if verbose:\n        print(\"\")\n    return m\n</code></pre>"},{"location":"reference/models/#rydberggpt.models.rydberg_decoder_wavefunction.RydbergDecoderWavefunction.get_x_magnetization","title":"<code>get_x_magnetization(samples: torch.Tensor)</code>","text":"<p>Calculates x magnetization of the model.</p> <p>Parameters:</p> Name Type Description Default <code>samples</code> <code>Tensor</code> <p>Samples drawn from model based on cond.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor containing the estimated x magnetization of each sample.</p> Source code in <code>src/rydberggpt/models/rydberg_decoder_wavefunction.py</code> <pre><code>def get_x_magnetization(\n    self,\n    samples: torch.Tensor,  # dtype=torch.int64\n):\n    \"\"\"\n    Calculates x magnetization of the model.\n\n    Args:\n        samples (torch.Tensor): Samples drawn from model based on cond.\n\n    Returns:\n        (torch.Tensor): A tensor containing the estimated x magnetization of each sample.\n    \"\"\"\n\n    # Create all possible states achievable by a single spin flip\n    flipped = (samples[:, None, :] + torch.eye(samples.shape[-1])[None, ...]) % 2\n    flipped = flipped.reshape(-1, samples.shape[-1])\n\n    # Get propabilities of sampled states and the single spin flipped states\n    sample_log_probs = self.get_log_probs(to_one_hot(samples, 2))\n    flipped_log_probs = self.get_log_probs(to_one_hot(flipped, 2))\n    flipped_log_probs = flipped_log_probs.reshape(-1, samples.shape[-1])\n\n    # Calculate ratio of the wavefunction for the sampled and flipped states\n    log_psi_ratio = 0.5 * (flipped_log_probs - sample_log_probs[:, None])\n    psi_ratio = torch.exp(log_psi_ratio)\n\n    x_magnetization = psi_ratio.sum(-1)\n    return x_magnetization\n</code></pre>"},{"location":"reference/models/#rydberggpt.models.rydberg_encoder_decoder","title":"<code>rydberggpt.models.rydberg_encoder_decoder</code>","text":""},{"location":"reference/models/#rydberggpt.models.rydberg_encoder_decoder.RydbergEncoderDecoder","title":"<code>RydbergEncoderDecoder</code>","text":"<p>               Bases: <code>EncoderDecoder</code></p> <p>RydbergTransformer is a specific implementation of the Encoder-Decoder architecture that uses an encoder and decoder composed of multiple layers of EncoderLayer and DecoderLayer modules, respectively. The encoder and decoder are followed by an embedding layer and a generator layer.</p> <p>Parameters:</p> Name Type Description Default <code>encoder</code> <code>Encoder[EncoderLayer]</code> <p>The encoder module.</p> required <code>decoder</code> <code>Decoder[DecoderLayer]</code> <p>The decoder module.</p> required <code>tgt_embed</code> <code>Module</code> <p>The target embeddings module.</p> required <code>generator</code> <code>Generator</code> <p>The generator module.</p> required <code>config</code> <code>dict</code> <p>A dictionary of configuration options. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> required Source code in <code>src/rydberggpt/models/rydberg_encoder_decoder.py</code> <pre><code>class RydbergEncoderDecoder(EncoderDecoder):\n    \"\"\"\n    RydbergTransformer is a specific implementation of the Encoder-Decoder architecture\n    that uses an encoder and decoder composed of multiple layers of EncoderLayer and DecoderLayer\n    modules, respectively. The encoder and decoder are followed by an embedding layer and a generator\n    layer.\n\n    Args:\n        encoder (Encoder[EncoderLayer]): The encoder module.\n        decoder (Decoder[DecoderLayer]): The decoder module.\n        tgt_embed (nn.Module): The target embeddings module.\n        generator (Generator): The generator module.\n        config (dict, optional): A dictionary of configuration options. Defaults to None.\n        **kwargs: Additional keyword arguments.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        encoder: Encoder,\n        decoder: Decoder,\n        src_embed: nn.Module,\n        tgt_embed: nn.Module,\n        generator: Generator,\n        config=None,\n    ):\n        super().__init__(encoder, decoder, src_embed, tgt_embed, generator)\n        self.config = config\n\n    @torch.no_grad()\n    def get_log_probs(self, x: torch.Tensor, cond: Batch):\n        \"\"\"\n        Compute the log probabilities of a given input tensor.\n\n        Parameters:\n            x (torch.Tensor): The input tensor.\n            cond (Batch): The conditional graph structure.\n\n        Returns:\n            (torch.Tensor): The log probabilities.\n        \"\"\"\n\n        if not hasattr(cond, \"num_graphs\"):\n            cond = Batch.from_data_list([cond.clone() for _ in range(len(x))])\n\n        assert (\n            len(x.shape) == 3 and x.shape[-1] == 2\n        ), \"The input must be one hot encoded\"\n\n        y = torch.zeros((x.shape[0], 1, x.shape[-1]))  # Initial token\n        y = y.to(x)  # Match dtype and device\n        y = torch.cat([y, x[:, :-1, :]], axis=-2)  # Append initial token to x\n\n        y = self.forward(y, cond)  # EncoderDecoder forward pass\n        y = self.generator(y)  # Conditional log probs\n\n        y = torch.sum(torch.sum(y * x, axis=-1), axis=-1)  # Log prob of full x\n\n        return y\n\n    @torch.no_grad()\n    def get_samples(\n        self,\n        batch_size: int,\n        cond: Batch,\n        num_atoms: int,\n        fmt_onehot: bool = True,\n    ):\n        \"\"\"\n        Generate samples using the forward pass and sampling from the conditional probabilities.\n        The samples can be returned either in one-hot encoding format or in label format,\n        according to the `fmt_onehot` argument.\n\n        Args:\n            batch_size (int): The number of samples to generate.\n            cond (torch_geometric.data.Batch): The batch of conditional graph structures.\n            num_atoms (int): The number of atoms to sample. For num_atoms &gt; num_nodes\n              in each graph within `cond`, the extra atoms are padded with zeros (onehot) or nan (label).\n            fmt_onehot (bool, optional): A flag to indicate whether to return the samples\n              in one-hot encoding format. If False, the samples are returned in label format. Defaults to True.\n\n        Returns:\n            (torch.Tensor): A tensor containing the generated samples. The shape of the tensor is (batch_size, num_atoms, 2) for one-hot encoding format, and (batch_size, num_atoms) for label format. The samples are padded according to the number of nodes in each graph within `cond`.\n        \"\"\"\n\n        if not hasattr(cond, \"num_graphs\"):\n            cond = Batch.from_data_list([cond.clone() for _ in range(batch_size)])\n\n        assert (\n            cond.num_graphs == batch_size\n        ), \"Incompatible arguments, batch_size ({}) does not match cond.num_graphs ({})\".format(\n            batch_size, cond.num_graphs\n        )\n\n        m = torch.zeros(batch_size, 1, 2, device=self.device)\n\n        for i in range(num_atoms):\n            print(\"{:&lt;80}\".format(f\"\\rGenerating atom {i+1}/{num_atoms}\"), end=\"\")\n            sys.stdout.flush()\n\n            y = self.forward(m, cond)  # EncoderDecoder forward pass\n            y = self.generator(y)  # Conditional log probs\n            y = y[:, -1, :]  # Next conditional log probs\n            y = torch.distributions.Categorical(logits=y).sample(\n                [\n                    1,\n                ]\n            )  # Sample from next conditional log probs\n            y = y.reshape(y.shape[1], 1)  # Reshape\n            y = to_one_hot(y, 2)  # Convert from label to one hot encoding\n\n            m = torch.cat((m, y), dim=-2)  # Append next sample to tensor\n\n        if fmt_onehot:\n            for i in range(m.shape[0]):\n                # Depending on num_nodes/num_atoms in graph pad samples with [0,0]\n                m[i, cond[i].num_nodes + 1 :, :] = 0\n\n            m = m[:, 1:, :]  # Remove initial token\n        else:\n            m = m[:, :, -1]\n\n            for i in range(m.shape[0]):\n                # Depending on num_nodes/num_atoms in graph pad samples with nan\n                m[i, cond[i].num_nodes + 1 :] = torch.nan\n\n            m = m[:, 1:]\n\n        print(\"\")\n        return m\n</code></pre>"},{"location":"reference/models/#rydberggpt.models.rydberg_encoder_decoder.RydbergEncoderDecoder.get_log_probs","title":"<code>get_log_probs(x: torch.Tensor, cond: Batch)</code>","text":"<p>Compute the log probabilities of a given input tensor.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>The input tensor.</p> required <code>cond</code> <code>Batch</code> <p>The conditional graph structure.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The log probabilities.</p> Source code in <code>src/rydberggpt/models/rydberg_encoder_decoder.py</code> <pre><code>@torch.no_grad()\ndef get_log_probs(self, x: torch.Tensor, cond: Batch):\n    \"\"\"\n    Compute the log probabilities of a given input tensor.\n\n    Parameters:\n        x (torch.Tensor): The input tensor.\n        cond (Batch): The conditional graph structure.\n\n    Returns:\n        (torch.Tensor): The log probabilities.\n    \"\"\"\n\n    if not hasattr(cond, \"num_graphs\"):\n        cond = Batch.from_data_list([cond.clone() for _ in range(len(x))])\n\n    assert (\n        len(x.shape) == 3 and x.shape[-1] == 2\n    ), \"The input must be one hot encoded\"\n\n    y = torch.zeros((x.shape[0], 1, x.shape[-1]))  # Initial token\n    y = y.to(x)  # Match dtype and device\n    y = torch.cat([y, x[:, :-1, :]], axis=-2)  # Append initial token to x\n\n    y = self.forward(y, cond)  # EncoderDecoder forward pass\n    y = self.generator(y)  # Conditional log probs\n\n    y = torch.sum(torch.sum(y * x, axis=-1), axis=-1)  # Log prob of full x\n\n    return y\n</code></pre>"},{"location":"reference/models/#rydberggpt.models.rydberg_encoder_decoder.RydbergEncoderDecoder.get_samples","title":"<code>get_samples(batch_size: int, cond: Batch, num_atoms: int, fmt_onehot: bool = True)</code>","text":"<p>Generate samples using the forward pass and sampling from the conditional probabilities. The samples can be returned either in one-hot encoding format or in label format, according to the <code>fmt_onehot</code> argument.</p> <p>Parameters:</p> Name Type Description Default <code>batch_size</code> <code>int</code> <p>The number of samples to generate.</p> required <code>cond</code> <code>Batch</code> <p>The batch of conditional graph structures.</p> required <code>num_atoms</code> <code>int</code> <p>The number of atoms to sample. For num_atoms &gt; num_nodes in each graph within <code>cond</code>, the extra atoms are padded with zeros (onehot) or nan (label).</p> required <code>fmt_onehot</code> <code>bool</code> <p>A flag to indicate whether to return the samples in one-hot encoding format. If False, the samples are returned in label format. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor containing the generated samples. The shape of the tensor is (batch_size, num_atoms, 2) for one-hot encoding format, and (batch_size, num_atoms) for label format. The samples are padded according to the number of nodes in each graph within <code>cond</code>.</p> Source code in <code>src/rydberggpt/models/rydberg_encoder_decoder.py</code> <pre><code>@torch.no_grad()\ndef get_samples(\n    self,\n    batch_size: int,\n    cond: Batch,\n    num_atoms: int,\n    fmt_onehot: bool = True,\n):\n    \"\"\"\n    Generate samples using the forward pass and sampling from the conditional probabilities.\n    The samples can be returned either in one-hot encoding format or in label format,\n    according to the `fmt_onehot` argument.\n\n    Args:\n        batch_size (int): The number of samples to generate.\n        cond (torch_geometric.data.Batch): The batch of conditional graph structures.\n        num_atoms (int): The number of atoms to sample. For num_atoms &gt; num_nodes\n          in each graph within `cond`, the extra atoms are padded with zeros (onehot) or nan (label).\n        fmt_onehot (bool, optional): A flag to indicate whether to return the samples\n          in one-hot encoding format. If False, the samples are returned in label format. Defaults to True.\n\n    Returns:\n        (torch.Tensor): A tensor containing the generated samples. The shape of the tensor is (batch_size, num_atoms, 2) for one-hot encoding format, and (batch_size, num_atoms) for label format. The samples are padded according to the number of nodes in each graph within `cond`.\n    \"\"\"\n\n    if not hasattr(cond, \"num_graphs\"):\n        cond = Batch.from_data_list([cond.clone() for _ in range(batch_size)])\n\n    assert (\n        cond.num_graphs == batch_size\n    ), \"Incompatible arguments, batch_size ({}) does not match cond.num_graphs ({})\".format(\n        batch_size, cond.num_graphs\n    )\n\n    m = torch.zeros(batch_size, 1, 2, device=self.device)\n\n    for i in range(num_atoms):\n        print(\"{:&lt;80}\".format(f\"\\rGenerating atom {i+1}/{num_atoms}\"), end=\"\")\n        sys.stdout.flush()\n\n        y = self.forward(m, cond)  # EncoderDecoder forward pass\n        y = self.generator(y)  # Conditional log probs\n        y = y[:, -1, :]  # Next conditional log probs\n        y = torch.distributions.Categorical(logits=y).sample(\n            [\n                1,\n            ]\n        )  # Sample from next conditional log probs\n        y = y.reshape(y.shape[1], 1)  # Reshape\n        y = to_one_hot(y, 2)  # Convert from label to one hot encoding\n\n        m = torch.cat((m, y), dim=-2)  # Append next sample to tensor\n\n    if fmt_onehot:\n        for i in range(m.shape[0]):\n            # Depending on num_nodes/num_atoms in graph pad samples with [0,0]\n            m[i, cond[i].num_nodes + 1 :, :] = 0\n\n        m = m[:, 1:, :]  # Remove initial token\n    else:\n        m = m[:, :, -1]\n\n        for i in range(m.shape[0]):\n            # Depending on num_nodes/num_atoms in graph pad samples with nan\n            m[i, cond[i].num_nodes + 1 :] = torch.nan\n\n        m = m[:, 1:]\n\n    print(\"\")\n    return m\n</code></pre>"},{"location":"reference/models/graph/","title":"Graph","text":""},{"location":"reference/models/graph/#rydberggpt.models.graph_embedding","title":"<code>rydberggpt.models.graph_embedding</code>","text":""},{"location":"reference/models/graph/#rydberggpt.models.graph_embedding.layers","title":"<code>layers</code>","text":""},{"location":"reference/models/graph/#rydberggpt.models.graph_embedding.layers.GraphLayer","title":"<code>GraphLayer</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>src/rydberggpt/models/graph_embedding/layers.py</code> <pre><code>class GraphLayer(nn.Module):\n    def __init__(self, graph_layer: nn.Module, norm_layer: nn.Module, dropout: float):\n        \"\"\"\n        A GraphLayer is a single layer in a graph neural network, consisting of\n        a graph layer, normalization layer, and dropout.\n\n        Args:\n            graph_layer (nn.Module): A graph layer, e.g., GCNConv, GATConv, etc.\n            norm_layer (nn.Module): A normalization layer, e.g., LayerNorm or BatchNorm.\n            dropout (float): Dropout probability.\n        \"\"\"\n        super(GraphLayer, self).__init__()\n        self.graph_layer = graph_layer\n        self.norm = norm_layer\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(\n        self, x: torch.Tensor, edge_index: Adj, edge_attr: OptTensor\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Forward pass through the GraphLayer.\n\n        Args:\n            x (torch.Tensor): Node feature matrix.\n            edge_index (Adj): Edge indices.\n            edge_attr (OptTensor): Edge feature matrix.\n\n        Returns:\n            (torch.Tensor): The output tensor after passing through the GraphLayer.\n        \"\"\"\n        x = self.graph_layer(x, edge_index, edge_attr)\n        x = F.relu(self.norm(x))\n        x = self.dropout(x)\n        return x\n</code></pre>"},{"location":"reference/models/graph/#rydberggpt.models.graph_embedding.layers.GraphLayer.__init__","title":"<code>__init__(graph_layer: nn.Module, norm_layer: nn.Module, dropout: float)</code>","text":"<p>A GraphLayer is a single layer in a graph neural network, consisting of a graph layer, normalization layer, and dropout.</p> <p>Parameters:</p> Name Type Description Default <code>graph_layer</code> <code>Module</code> <p>A graph layer, e.g., GCNConv, GATConv, etc.</p> required <code>norm_layer</code> <code>Module</code> <p>A normalization layer, e.g., LayerNorm or BatchNorm.</p> required <code>dropout</code> <code>float</code> <p>Dropout probability.</p> required Source code in <code>src/rydberggpt/models/graph_embedding/layers.py</code> <pre><code>def __init__(self, graph_layer: nn.Module, norm_layer: nn.Module, dropout: float):\n    \"\"\"\n    A GraphLayer is a single layer in a graph neural network, consisting of\n    a graph layer, normalization layer, and dropout.\n\n    Args:\n        graph_layer (nn.Module): A graph layer, e.g., GCNConv, GATConv, etc.\n        norm_layer (nn.Module): A normalization layer, e.g., LayerNorm or BatchNorm.\n        dropout (float): Dropout probability.\n    \"\"\"\n    super(GraphLayer, self).__init__()\n    self.graph_layer = graph_layer\n    self.norm = norm_layer\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/models/graph/#rydberggpt.models.graph_embedding.layers.GraphLayer.forward","title":"<code>forward(x: torch.Tensor, edge_index: Adj, edge_attr: OptTensor) -&gt; torch.Tensor</code>","text":"<p>Forward pass through the GraphLayer.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Node feature matrix.</p> required <code>edge_index</code> <code>Adj</code> <p>Edge indices.</p> required <code>edge_attr</code> <code>OptTensor</code> <p>Edge feature matrix.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The output tensor after passing through the GraphLayer.</p> Source code in <code>src/rydberggpt/models/graph_embedding/layers.py</code> <pre><code>def forward(\n    self, x: torch.Tensor, edge_index: Adj, edge_attr: OptTensor\n) -&gt; torch.Tensor:\n    \"\"\"\n    Forward pass through the GraphLayer.\n\n    Args:\n        x (torch.Tensor): Node feature matrix.\n        edge_index (Adj): Edge indices.\n        edge_attr (OptTensor): Edge feature matrix.\n\n    Returns:\n        (torch.Tensor): The output tensor after passing through the GraphLayer.\n    \"\"\"\n    x = self.graph_layer(x, edge_index, edge_attr)\n    x = F.relu(self.norm(x))\n    x = self.dropout(x)\n    return x\n</code></pre>"},{"location":"reference/models/graph/#rydberggpt.models.graph_embedding.models","title":"<code>models</code>","text":""},{"location":"reference/models/graph/#rydberggpt.models.graph_embedding.models.GraphEmbedding","title":"<code>GraphEmbedding</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>src/rydberggpt/models/graph_embedding/models.py</code> <pre><code>class GraphEmbedding(torch.nn.Module):\n    def __init__(\n        self,\n        graph_layer: Type[Callable],\n        in_node_dim: int,\n        d_hidden: int,\n        d_model: int,\n        num_layers: int,\n        dropout: float = 0.1,\n    ) -&gt; None:\n        \"\"\"\n        GraphEmbedding class for creating a graph embedding with multiple layers.\n\n        Args:\n            graph_layer (Type[Callable]): The graph layer to be used in the embedding.\n            in_node_dim (int): The input node dimension. (omega, delta, beta)\n            d_hidden (int): The hidden dimension size.\n            d_model (int): The output node dimension.\n            num_layers (int): The number of layers in the graph embedding.\n            dropout (float, optional): The dropout rate. Defaults to 0.1.\n        \"\"\"\n        super(GraphEmbedding, self).__init__()\n\n        self.graph_layer = graph_layer\n        self.layers = ModuleList()\n        self.layers.append(\n            GraphLayer(\n                self.graph_layer(in_node_dim, d_hidden), LayerNorm(d_hidden), dropout\n            )\n        )\n\n        for _ in range(num_layers - 2):\n            self.layers.append(\n                GraphLayer(\n                    self.graph_layer(d_hidden, d_hidden), LayerNorm(d_hidden), dropout\n                )\n            )\n\n        self.layers.append(self.graph_layer(d_hidden, d_model))\n        self.final_norm = LayerNorm(d_model)\n\n    def forward(self, data: Data) -&gt; Tensor:\n        \"\"\"\n        Forward pass through the graph embedding layers.\n\n        Args:\n            data (Data): The input graph data.\n\n        Returns:\n            (Tensor): The output tensor with reshaped dimensions.\n        \"\"\"\n        # [..., num_features], [2, ...] [...]\n        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n\n        for layer in self.layers[:-1]:\n            # [..., num_features]\n            x = layer(x, edge_index, edge_attr)\n\n        # [..., d_model]\n        x = self.final_norm(self.layers[-1](x, edge_index, edge_attr))\n\n        x, batch_mask = to_dense_batch(x, data.batch)\n\n        # [B, N, d_model], where N is the number of nodes or the number of atoms\n        return x, batch_mask\n</code></pre>"},{"location":"reference/models/graph/#rydberggpt.models.graph_embedding.models.GraphEmbedding.__init__","title":"<code>__init__(graph_layer: Type[Callable], in_node_dim: int, d_hidden: int, d_model: int, num_layers: int, dropout: float = 0.1) -&gt; None</code>","text":"<p>GraphEmbedding class for creating a graph embedding with multiple layers.</p> <p>Parameters:</p> Name Type Description Default <code>graph_layer</code> <code>Type[Callable]</code> <p>The graph layer to be used in the embedding.</p> required <code>in_node_dim</code> <code>int</code> <p>The input node dimension. (omega, delta, beta)</p> required <code>d_hidden</code> <code>int</code> <p>The hidden dimension size.</p> required <code>d_model</code> <code>int</code> <p>The output node dimension.</p> required <code>num_layers</code> <code>int</code> <p>The number of layers in the graph embedding.</p> required <code>dropout</code> <code>float</code> <p>The dropout rate. Defaults to 0.1.</p> <code>0.1</code> Source code in <code>src/rydberggpt/models/graph_embedding/models.py</code> <pre><code>def __init__(\n    self,\n    graph_layer: Type[Callable],\n    in_node_dim: int,\n    d_hidden: int,\n    d_model: int,\n    num_layers: int,\n    dropout: float = 0.1,\n) -&gt; None:\n    \"\"\"\n    GraphEmbedding class for creating a graph embedding with multiple layers.\n\n    Args:\n        graph_layer (Type[Callable]): The graph layer to be used in the embedding.\n        in_node_dim (int): The input node dimension. (omega, delta, beta)\n        d_hidden (int): The hidden dimension size.\n        d_model (int): The output node dimension.\n        num_layers (int): The number of layers in the graph embedding.\n        dropout (float, optional): The dropout rate. Defaults to 0.1.\n    \"\"\"\n    super(GraphEmbedding, self).__init__()\n\n    self.graph_layer = graph_layer\n    self.layers = ModuleList()\n    self.layers.append(\n        GraphLayer(\n            self.graph_layer(in_node_dim, d_hidden), LayerNorm(d_hidden), dropout\n        )\n    )\n\n    for _ in range(num_layers - 2):\n        self.layers.append(\n            GraphLayer(\n                self.graph_layer(d_hidden, d_hidden), LayerNorm(d_hidden), dropout\n            )\n        )\n\n    self.layers.append(self.graph_layer(d_hidden, d_model))\n    self.final_norm = LayerNorm(d_model)\n</code></pre>"},{"location":"reference/models/graph/#rydberggpt.models.graph_embedding.models.GraphEmbedding.forward","title":"<code>forward(data: Data) -&gt; Tensor</code>","text":"<p>Forward pass through the graph embedding layers.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Data</code> <p>The input graph data.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The output tensor with reshaped dimensions.</p> Source code in <code>src/rydberggpt/models/graph_embedding/models.py</code> <pre><code>def forward(self, data: Data) -&gt; Tensor:\n    \"\"\"\n    Forward pass through the graph embedding layers.\n\n    Args:\n        data (Data): The input graph data.\n\n    Returns:\n        (Tensor): The output tensor with reshaped dimensions.\n    \"\"\"\n    # [..., num_features], [2, ...] [...]\n    x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n\n    for layer in self.layers[:-1]:\n        # [..., num_features]\n        x = layer(x, edge_index, edge_attr)\n\n    # [..., d_model]\n    x = self.final_norm(self.layers[-1](x, edge_index, edge_attr))\n\n    x, batch_mask = to_dense_batch(x, data.batch)\n\n    # [B, N, d_model], where N is the number of nodes or the number of atoms\n    return x, batch_mask\n</code></pre>"},{"location":"reference/models/transformer/","title":"Transformer","text":""},{"location":"reference/models/transformer/#rydberggpt.models.transformer","title":"<code>rydberggpt.models.transformer</code>","text":""},{"location":"reference/models/transformer/#rydberggpt.models.transformer.layers","title":"<code>layers</code>","text":""},{"location":"reference/models/transformer/#rydberggpt.models.transformer.layers.DecoderLayer","title":"<code>DecoderLayer</code>","text":"<p>               Bases: <code>Module</code></p> <p>Decoder is made of self-attn, src-attn, and feed forward.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>int</code> <p>The input size. (d_model)</p> required <code>self_attn</code> <code>MultiheadAttention</code> <p>The self-attention module.</p> required <code>src_attn</code> <code>MultiheadAttention</code> <p>The source-attention module.</p> required <code>feed_forward</code> <code>PositionwiseFeedForward</code> <p>The feed forward module.</p> required <code>dropout</code> <code>float</code> <p>The dropout rate.</p> required Source code in <code>src/rydberggpt/models/transformer/layers.py</code> <pre><code>class DecoderLayer(nn.Module):\n    \"\"\"\n    Decoder is made of self-attn, src-attn, and feed forward.\n\n    Args:\n        size (int): The input size. (d_model)\n        self_attn (nn.MultiheadAttention): The self-attention module.\n        src_attn (nn.MultiheadAttention): The source-attention module.\n        feed_forward (PositionwiseFeedForward): The feed forward module.\n        dropout (float): The dropout rate.\n    \"\"\"\n\n    def __init__(\n        self,\n        size: int,\n        self_attn: nn.MultiheadAttention,\n        src_attn: nn.MultiheadAttention,\n        feed_forward: PositionwiseFeedForward,\n        dropout: float,\n    ):\n        super(DecoderLayer, self).__init__()\n        self.size = size\n        self.self_attn = self_attn\n        self.src_attn = src_attn\n        self.feed_forward = feed_forward\n        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n\n    def forward(\n        self, x: torch.Tensor, memory: torch.Tensor, batch_mask: torch.Tensor\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Compute the forward pass through the decoder.\n\n        Args:\n            x (torch.Tensor): The input tensor.\n            memory (torch.Tensor): The memory tensor.\n            batch_mask (torch.Tensor): The mask tensor for batches.\n\n        Returns:\n            (torch.Tensor): The output tensor.\n        \"\"\"\n\n        causal_attn_mask = torch.meshgrid(\n            torch.arange(x.shape[-2], device=x.device),\n            torch.arange(x.shape[-2], device=x.device),\n            indexing=\"ij\",\n        )\n        causal_attn_mask = causal_attn_mask[0] &gt;= causal_attn_mask[1]\n        causal_attn_mask = torch.logical_not(causal_attn_mask)\n\n        batch_key_mask = batch_mask\n        batch_key_mask = torch.logical_not(batch_key_mask)\n\n        m = memory\n        x = self.sublayer[0](\n            x, lambda x: self.self_attn(x, x, x, attn_mask=causal_attn_mask)[0]\n        )\n        x = self.sublayer[1](\n            x, lambda x: self.src_attn(x, m, m, key_padding_mask=batch_key_mask)[0]\n        )\n        return self.sublayer[2](x, self.feed_forward)\n</code></pre>"},{"location":"reference/models/transformer/#rydberggpt.models.transformer.layers.DecoderLayer.forward","title":"<code>forward(x: torch.Tensor, memory: torch.Tensor, batch_mask: torch.Tensor) -&gt; torch.Tensor</code>","text":"<p>Compute the forward pass through the decoder.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>The input tensor.</p> required <code>memory</code> <code>Tensor</code> <p>The memory tensor.</p> required <code>batch_mask</code> <code>Tensor</code> <p>The mask tensor for batches.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The output tensor.</p> Source code in <code>src/rydberggpt/models/transformer/layers.py</code> <pre><code>def forward(\n    self, x: torch.Tensor, memory: torch.Tensor, batch_mask: torch.Tensor\n) -&gt; torch.Tensor:\n    \"\"\"\n    Compute the forward pass through the decoder.\n\n    Args:\n        x (torch.Tensor): The input tensor.\n        memory (torch.Tensor): The memory tensor.\n        batch_mask (torch.Tensor): The mask tensor for batches.\n\n    Returns:\n        (torch.Tensor): The output tensor.\n    \"\"\"\n\n    causal_attn_mask = torch.meshgrid(\n        torch.arange(x.shape[-2], device=x.device),\n        torch.arange(x.shape[-2], device=x.device),\n        indexing=\"ij\",\n    )\n    causal_attn_mask = causal_attn_mask[0] &gt;= causal_attn_mask[1]\n    causal_attn_mask = torch.logical_not(causal_attn_mask)\n\n    batch_key_mask = batch_mask\n    batch_key_mask = torch.logical_not(batch_key_mask)\n\n    m = memory\n    x = self.sublayer[0](\n        x, lambda x: self.self_attn(x, x, x, attn_mask=causal_attn_mask)[0]\n    )\n    x = self.sublayer[1](\n        x, lambda x: self.src_attn(x, m, m, key_padding_mask=batch_key_mask)[0]\n    )\n    return self.sublayer[2](x, self.feed_forward)\n</code></pre>"},{"location":"reference/models/transformer/#rydberggpt.models.transformer.layers.EncoderLayer","title":"<code>EncoderLayer</code>","text":"<p>               Bases: <code>Module</code></p> <p>Encoder is made up of self-attn and feed forward.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>int</code> <p>The input size. (d_model)</p> required <code>self_attn</code> <code>MultiheadAttention</code> <p>The self-attention module.</p> required <code>feed_forward</code> <code>PositionwiseFeedForward</code> <p>The feed forward module.</p> required <code>dropout</code> <code>float</code> <p>The dropout rate.</p> required Source code in <code>src/rydberggpt/models/transformer/layers.py</code> <pre><code>class EncoderLayer(nn.Module):\n    \"\"\"\n    Encoder is made up of self-attn and feed forward.\n\n    Args:\n        size (int): The input size. (d_model)\n        self_attn (nn.MultiheadAttention): The self-attention module.\n        feed_forward (PositionwiseFeedForward): The feed forward module.\n        dropout (float): The dropout rate.\n    \"\"\"\n\n    def __init__(\n        self,\n        size: int,\n        self_attn: nn.MultiheadAttention,\n        feed_forward: PositionwiseFeedForward,\n        dropout: float,\n    ):\n        super(EncoderLayer, self).__init__()\n        self.self_attn = self_attn\n        self.feed_forward = feed_forward\n        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n        self.size = size\n\n    def forward(self, x: torch.Tensor, batch_mask: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Compute the forward pass through the encoder.\n\n        Args:\n            x (torch.Tensor): The input tensor.\n            batch_mask (torch.Tensor): The mask tensor for batches.\n\n        Returns:\n            (torch.Tensor): The output tensor.\n        \"\"\"\n\n        batch_key_mask = batch_mask\n        batch_key_mask = torch.logical_not(batch_key_mask)\n\n        x = self.sublayer[0](\n            x,\n            lambda x: torch.nan_to_num(\n                self.self_attn(x, x, x, key_padding_mask=batch_key_mask)[0]\n            ),\n        )\n        return self.sublayer[1](x, self.feed_forward)\n</code></pre>"},{"location":"reference/models/transformer/#rydberggpt.models.transformer.layers.EncoderLayer.forward","title":"<code>forward(x: torch.Tensor, batch_mask: torch.Tensor) -&gt; torch.Tensor</code>","text":"<p>Compute the forward pass through the encoder.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>The input tensor.</p> required <code>batch_mask</code> <code>Tensor</code> <p>The mask tensor for batches.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The output tensor.</p> Source code in <code>src/rydberggpt/models/transformer/layers.py</code> <pre><code>def forward(self, x: torch.Tensor, batch_mask: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Compute the forward pass through the encoder.\n\n    Args:\n        x (torch.Tensor): The input tensor.\n        batch_mask (torch.Tensor): The mask tensor for batches.\n\n    Returns:\n        (torch.Tensor): The output tensor.\n    \"\"\"\n\n    batch_key_mask = batch_mask\n    batch_key_mask = torch.logical_not(batch_key_mask)\n\n    x = self.sublayer[0](\n        x,\n        lambda x: torch.nan_to_num(\n            self.self_attn(x, x, x, key_padding_mask=batch_key_mask)[0]\n        ),\n    )\n    return self.sublayer[1](x, self.feed_forward)\n</code></pre>"},{"location":"reference/models/transformer/#rydberggpt.models.transformer.models","title":"<code>models</code>","text":""},{"location":"reference/models/transformer/#rydberggpt.models.transformer.models.Decoder","title":"<code>Decoder</code>","text":"<p>               Bases: <code>Module</code></p> <p>The core of the transformer, which consists of a stack of decoder layers.</p> Source code in <code>src/rydberggpt/models/transformer/models.py</code> <pre><code>class Decoder(nn.Module):\n    \"\"\"\n    The core of the transformer, which consists of a stack of decoder layers.\n    \"\"\"\n\n    def __init__(self, layer: nn.Module, n_layers: int):\n        \"\"\"\n        Initialize the Decoder class.\n\n        Args:\n            layer (nn.Module): A single instance of the decoder layer to be cloned.\n            n_layers (int): The number of decoder layers in the stack.\n        \"\"\"\n        super(Decoder, self).__init__()\n        self.layers = clones(layer, n_layers)\n        self.norm = nn.LayerNorm(layer.size)\n\n    def forward(\n        self, x: torch.Tensor, memory: torch.Tensor, batch_mask: torch.Tensor\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Pass the (masked) input through all layers of the decoder.\n\n        Args:\n            x (torch.Tensor): The input tensor to the decoder of shape (batch_size, seq_length, d_model).\n            memory (torch.Tensor): The memory tensor, typically the output of the encoder.\n            batch_mask (torch.Tensor): The mask tensor for batches.\n\n        Returns:\n            (torch.Tensor): The output tensor after passing through all layers of the decoder of shape (batch_size, seq_length, d_model).\n        \"\"\"\n        for layer in self.layers:\n            x = layer(x, memory, batch_mask=batch_mask)\n        return self.norm(x)  # [batch_size, seq_len, d_model]\n</code></pre>"},{"location":"reference/models/transformer/#rydberggpt.models.transformer.models.Decoder.__init__","title":"<code>__init__(layer: nn.Module, n_layers: int)</code>","text":"<p>Initialize the Decoder class.</p> <p>Parameters:</p> Name Type Description Default <code>layer</code> <code>Module</code> <p>A single instance of the decoder layer to be cloned.</p> required <code>n_layers</code> <code>int</code> <p>The number of decoder layers in the stack.</p> required Source code in <code>src/rydberggpt/models/transformer/models.py</code> <pre><code>def __init__(self, layer: nn.Module, n_layers: int):\n    \"\"\"\n    Initialize the Decoder class.\n\n    Args:\n        layer (nn.Module): A single instance of the decoder layer to be cloned.\n        n_layers (int): The number of decoder layers in the stack.\n    \"\"\"\n    super(Decoder, self).__init__()\n    self.layers = clones(layer, n_layers)\n    self.norm = nn.LayerNorm(layer.size)\n</code></pre>"},{"location":"reference/models/transformer/#rydberggpt.models.transformer.models.Decoder.forward","title":"<code>forward(x: torch.Tensor, memory: torch.Tensor, batch_mask: torch.Tensor) -&gt; torch.Tensor</code>","text":"<p>Pass the (masked) input through all layers of the decoder.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>The input tensor to the decoder of shape (batch_size, seq_length, d_model).</p> required <code>memory</code> <code>Tensor</code> <p>The memory tensor, typically the output of the encoder.</p> required <code>batch_mask</code> <code>Tensor</code> <p>The mask tensor for batches.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The output tensor after passing through all layers of the decoder of shape (batch_size, seq_length, d_model).</p> Source code in <code>src/rydberggpt/models/transformer/models.py</code> <pre><code>def forward(\n    self, x: torch.Tensor, memory: torch.Tensor, batch_mask: torch.Tensor\n) -&gt; torch.Tensor:\n    \"\"\"\n    Pass the (masked) input through all layers of the decoder.\n\n    Args:\n        x (torch.Tensor): The input tensor to the decoder of shape (batch_size, seq_length, d_model).\n        memory (torch.Tensor): The memory tensor, typically the output of the encoder.\n        batch_mask (torch.Tensor): The mask tensor for batches.\n\n    Returns:\n        (torch.Tensor): The output tensor after passing through all layers of the decoder of shape (batch_size, seq_length, d_model).\n    \"\"\"\n    for layer in self.layers:\n        x = layer(x, memory, batch_mask=batch_mask)\n    return self.norm(x)  # [batch_size, seq_len, d_model]\n</code></pre>"},{"location":"reference/models/transformer/#rydberggpt.models.transformer.models.Encoder","title":"<code>Encoder</code>","text":"<p>               Bases: <code>Module</code></p> <p>The core encoder, which consists of a stack of N layers.</p> Source code in <code>src/rydberggpt/models/transformer/models.py</code> <pre><code>class Encoder(nn.Module):\n    \"\"\"\n    The core encoder, which consists of a stack of N layers.\n    \"\"\"\n\n    def __init__(self, layer: nn.Module, N: int):\n        \"\"\"\n        Initialize the Encoder class.\n\n        Args:\n            layer (nn.Module): A single instance of the encoder layer to be cloned.\n            N (int): The number of encoder layers in the stack.\n        \"\"\"\n        super(Encoder, self).__init__()\n        self.layers = clones(layer, N)\n        self.norm = nn.LayerNorm(layer.size)\n\n    def forward(self, x: torch.Tensor, batch_mask: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Pass the input through each layer in turn.\n\n        Args:\n            x (torch.Tensor): The input tensor to the encoder of shape (batch_size, seq_length, d_model).\n            batch_mask (torch.Tensor): The mask tensor for batches.\n\n        Returns:\n            (torch.Tensor): The output tensor after passing through all layers of the encoder,\n                          with the same shape as the input tensor (batch_size, seq_length, d_model).\n        \"\"\"\n        for layer in self.layers:\n            x = layer(x, batch_mask=batch_mask)\n        return self.norm(x)  # [batch_size, seq_length, d_model]\n</code></pre>"},{"location":"reference/models/transformer/#rydberggpt.models.transformer.models.Encoder.__init__","title":"<code>__init__(layer: nn.Module, N: int)</code>","text":"<p>Initialize the Encoder class.</p> <p>Parameters:</p> Name Type Description Default <code>layer</code> <code>Module</code> <p>A single instance of the encoder layer to be cloned.</p> required <code>N</code> <code>int</code> <p>The number of encoder layers in the stack.</p> required Source code in <code>src/rydberggpt/models/transformer/models.py</code> <pre><code>def __init__(self, layer: nn.Module, N: int):\n    \"\"\"\n    Initialize the Encoder class.\n\n    Args:\n        layer (nn.Module): A single instance of the encoder layer to be cloned.\n        N (int): The number of encoder layers in the stack.\n    \"\"\"\n    super(Encoder, self).__init__()\n    self.layers = clones(layer, N)\n    self.norm = nn.LayerNorm(layer.size)\n</code></pre>"},{"location":"reference/models/transformer/#rydberggpt.models.transformer.models.Encoder.forward","title":"<code>forward(x: torch.Tensor, batch_mask: torch.Tensor) -&gt; torch.Tensor</code>","text":"<p>Pass the input through each layer in turn.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>The input tensor to the encoder of shape (batch_size, seq_length, d_model).</p> required <code>batch_mask</code> <code>Tensor</code> <p>The mask tensor for batches.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The output tensor after passing through all layers of the encoder,           with the same shape as the input tensor (batch_size, seq_length, d_model).</p> Source code in <code>src/rydberggpt/models/transformer/models.py</code> <pre><code>def forward(self, x: torch.Tensor, batch_mask: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Pass the input through each layer in turn.\n\n    Args:\n        x (torch.Tensor): The input tensor to the encoder of shape (batch_size, seq_length, d_model).\n        batch_mask (torch.Tensor): The mask tensor for batches.\n\n    Returns:\n        (torch.Tensor): The output tensor after passing through all layers of the encoder,\n                      with the same shape as the input tensor (batch_size, seq_length, d_model).\n    \"\"\"\n    for layer in self.layers:\n        x = layer(x, batch_mask=batch_mask)\n    return self.norm(x)  # [batch_size, seq_length, d_model]\n</code></pre>"},{"location":"reference/models/transformer/#rydberggpt.models.transformer.models.EncoderDecoder","title":"<code>EncoderDecoder</code>","text":"<p>               Bases: <code>LightningModule</code></p> <p>A standard Encoder-Decoder architecture. Base for this and many other models.</p> Source code in <code>src/rydberggpt/models/transformer/models.py</code> <pre><code>class EncoderDecoder(pl.LightningModule):\n    \"\"\"\n    A standard Encoder-Decoder architecture. Base for this and many other models.\n    \"\"\"\n\n    def __init__(\n        self,\n        encoder: nn.Module,\n        decoder: nn.Module,\n        src_embed: nn.Module,\n        tgt_embed: nn.Module,\n        generator: nn.Module,\n    ):\n        \"\"\"\n        Initialize the EncoderDecoder class.\n\n        Args:\n            encoder (nn.Module): The encoder module.\n            decoder (nn.Module): The decoder module.\n            tgt_embed (nn.Module): The target embedding module.\n            generator (nn.Module): The generator module.\n        \"\"\"\n        super(EncoderDecoder, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.src_embed = src_embed\n        self.tgt_embed = tgt_embed\n        self.generator = generator\n\n    def forward(self, tgt: torch.Tensor, src: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Take in and process masked src and target sequences.\n\n        Args:\n            tgt (torch.Tensor): The target tensor of shape (batch_size, tgt_seq_length, d_model_tgt).\n            src (torch.Tensor): The source tensor of shape (batch_size, src_seq_length, d_model_src).\n\n        Returns:\n            (torch.Tensor): The output tensor after passing through the encoder-decoder architecture,\n                          with shape (batch_size, tgt_seq_length, d_model).\n        \"\"\"\n\n        memory, batch_mask = self.encode(src)\n\n        return self.decode(tgt, memory, batch_mask)\n\n    def encode(self, src: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Encode the source tensor.\n\n        Args:\n            src (torch.Tensor): The source tensor of shape (batch_size, src_seq_length, d_model_src).\n\n        Returns:\n            (torch.Tensor): The encoded tensor of shape (batch_size, src_seq_length, d_model_tgt).\n        \"\"\"\n\n        x, batch_mask = self.src_embed(src)\n\n        return self.encoder(x, batch_mask=batch_mask), batch_mask\n\n    def decode(\n        self, tgt: torch.Tensor, memory: torch.Tensor, batch_mask: torch.Tensor\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Decode the target tensor using the memory tensor.\n\n        Args:\n            tgt (torch.Tensor): The target tensor of shape (batch_size, tgt_seq_length, d_model_tgt).\n            memory (torch.Tensor): The memory tensor of shape (batch_size, src_seq_length, d_model).\n\n        Returns:\n            (torch.Tensor): The decoded tensor of shape (batch_size, tgt_seq_length, d_model).\n        \"\"\"\n        return self.decoder(self.tgt_embed(tgt), memory, batch_mask=batch_mask)\n</code></pre>"},{"location":"reference/models/transformer/#rydberggpt.models.transformer.models.EncoderDecoder.__init__","title":"<code>__init__(encoder: nn.Module, decoder: nn.Module, src_embed: nn.Module, tgt_embed: nn.Module, generator: nn.Module)</code>","text":"<p>Initialize the EncoderDecoder class.</p> <p>Parameters:</p> Name Type Description Default <code>encoder</code> <code>Module</code> <p>The encoder module.</p> required <code>decoder</code> <code>Module</code> <p>The decoder module.</p> required <code>tgt_embed</code> <code>Module</code> <p>The target embedding module.</p> required <code>generator</code> <code>Module</code> <p>The generator module.</p> required Source code in <code>src/rydberggpt/models/transformer/models.py</code> <pre><code>def __init__(\n    self,\n    encoder: nn.Module,\n    decoder: nn.Module,\n    src_embed: nn.Module,\n    tgt_embed: nn.Module,\n    generator: nn.Module,\n):\n    \"\"\"\n    Initialize the EncoderDecoder class.\n\n    Args:\n        encoder (nn.Module): The encoder module.\n        decoder (nn.Module): The decoder module.\n        tgt_embed (nn.Module): The target embedding module.\n        generator (nn.Module): The generator module.\n    \"\"\"\n    super(EncoderDecoder, self).__init__()\n    self.encoder = encoder\n    self.decoder = decoder\n    self.src_embed = src_embed\n    self.tgt_embed = tgt_embed\n    self.generator = generator\n</code></pre>"},{"location":"reference/models/transformer/#rydberggpt.models.transformer.models.EncoderDecoder.decode","title":"<code>decode(tgt: torch.Tensor, memory: torch.Tensor, batch_mask: torch.Tensor) -&gt; torch.Tensor</code>","text":"<p>Decode the target tensor using the memory tensor.</p> <p>Parameters:</p> Name Type Description Default <code>tgt</code> <code>Tensor</code> <p>The target tensor of shape (batch_size, tgt_seq_length, d_model_tgt).</p> required <code>memory</code> <code>Tensor</code> <p>The memory tensor of shape (batch_size, src_seq_length, d_model).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The decoded tensor of shape (batch_size, tgt_seq_length, d_model).</p> Source code in <code>src/rydberggpt/models/transformer/models.py</code> <pre><code>def decode(\n    self, tgt: torch.Tensor, memory: torch.Tensor, batch_mask: torch.Tensor\n) -&gt; torch.Tensor:\n    \"\"\"\n    Decode the target tensor using the memory tensor.\n\n    Args:\n        tgt (torch.Tensor): The target tensor of shape (batch_size, tgt_seq_length, d_model_tgt).\n        memory (torch.Tensor): The memory tensor of shape (batch_size, src_seq_length, d_model).\n\n    Returns:\n        (torch.Tensor): The decoded tensor of shape (batch_size, tgt_seq_length, d_model).\n    \"\"\"\n    return self.decoder(self.tgt_embed(tgt), memory, batch_mask=batch_mask)\n</code></pre>"},{"location":"reference/models/transformer/#rydberggpt.models.transformer.models.EncoderDecoder.encode","title":"<code>encode(src: torch.Tensor) -&gt; torch.Tensor</code>","text":"<p>Encode the source tensor.</p> <p>Parameters:</p> Name Type Description Default <code>src</code> <code>Tensor</code> <p>The source tensor of shape (batch_size, src_seq_length, d_model_src).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The encoded tensor of shape (batch_size, src_seq_length, d_model_tgt).</p> Source code in <code>src/rydberggpt/models/transformer/models.py</code> <pre><code>def encode(self, src: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Encode the source tensor.\n\n    Args:\n        src (torch.Tensor): The source tensor of shape (batch_size, src_seq_length, d_model_src).\n\n    Returns:\n        (torch.Tensor): The encoded tensor of shape (batch_size, src_seq_length, d_model_tgt).\n    \"\"\"\n\n    x, batch_mask = self.src_embed(src)\n\n    return self.encoder(x, batch_mask=batch_mask), batch_mask\n</code></pre>"},{"location":"reference/models/transformer/#rydberggpt.models.transformer.models.EncoderDecoder.forward","title":"<code>forward(tgt: torch.Tensor, src: torch.Tensor) -&gt; torch.Tensor</code>","text":"<p>Take in and process masked src and target sequences.</p> <p>Parameters:</p> Name Type Description Default <code>tgt</code> <code>Tensor</code> <p>The target tensor of shape (batch_size, tgt_seq_length, d_model_tgt).</p> required <code>src</code> <code>Tensor</code> <p>The source tensor of shape (batch_size, src_seq_length, d_model_src).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The output tensor after passing through the encoder-decoder architecture,           with shape (batch_size, tgt_seq_length, d_model).</p> Source code in <code>src/rydberggpt/models/transformer/models.py</code> <pre><code>def forward(self, tgt: torch.Tensor, src: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Take in and process masked src and target sequences.\n\n    Args:\n        tgt (torch.Tensor): The target tensor of shape (batch_size, tgt_seq_length, d_model_tgt).\n        src (torch.Tensor): The source tensor of shape (batch_size, src_seq_length, d_model_src).\n\n    Returns:\n        (torch.Tensor): The output tensor after passing through the encoder-decoder architecture,\n                      with shape (batch_size, tgt_seq_length, d_model).\n    \"\"\"\n\n    memory, batch_mask = self.encode(src)\n\n    return self.decode(tgt, memory, batch_mask)\n</code></pre>"},{"location":"reference/models/transformer/#rydberggpt.models.transformer.models.Generator","title":"<code>Generator</code>","text":"<p>               Bases: <code>Module</code></p> <p>Linear + softmax layer for generation step. vocab_size for Rydberg is 2.</p> Source code in <code>src/rydberggpt/models/transformer/models.py</code> <pre><code>class Generator(nn.Module):\n    \"\"\"\n    Linear + softmax layer for generation step. vocab_size for Rydberg is 2.\n    \"\"\"\n\n    def __init__(self, d_model: int, vocab_size: int):\n        \"\"\"\n        Initialize the Generator class.\n\n        Args:\n            d_model (int): The dimension of the input features (i.e., the last dimension of the input tensor).\n            vocab_size (int): The size of the vocabulary, which determines the last dimension of the output tensor.\n        \"\"\"\n        super(Generator, self).__init__()\n        self.proj = nn.Linear(d_model, vocab_size)  # [batch_size, seq_len, vocab_size]\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Compute the forward pass of the Generator.\n\n        Args:\n            x (torch.Tensor): The input tensor of shape (batch_size, seq_length, d_model).\n\n        Returns:\n            (torch.Tensor): The output tensor of shape (batch_size, seq_length, vocab_size),\n                          with log-softmax applied along the last dimension.\n        \"\"\"\n\n        proj_offset = self.proj(x) + 1e-10\n        return F.log_softmax(proj_offset, dim=-1)  # [batch_size, seq_len, vocab_size]\n</code></pre>"},{"location":"reference/models/transformer/#rydberggpt.models.transformer.models.Generator.__init__","title":"<code>__init__(d_model: int, vocab_size: int)</code>","text":"<p>Initialize the Generator class.</p> <p>Parameters:</p> Name Type Description Default <code>d_model</code> <code>int</code> <p>The dimension of the input features (i.e., the last dimension of the input tensor).</p> required <code>vocab_size</code> <code>int</code> <p>The size of the vocabulary, which determines the last dimension of the output tensor.</p> required Source code in <code>src/rydberggpt/models/transformer/models.py</code> <pre><code>def __init__(self, d_model: int, vocab_size: int):\n    \"\"\"\n    Initialize the Generator class.\n\n    Args:\n        d_model (int): The dimension of the input features (i.e., the last dimension of the input tensor).\n        vocab_size (int): The size of the vocabulary, which determines the last dimension of the output tensor.\n    \"\"\"\n    super(Generator, self).__init__()\n    self.proj = nn.Linear(d_model, vocab_size)  # [batch_size, seq_len, vocab_size]\n</code></pre>"},{"location":"reference/models/transformer/#rydberggpt.models.transformer.models.Generator.forward","title":"<code>forward(x: torch.Tensor) -&gt; torch.Tensor</code>","text":"<p>Compute the forward pass of the Generator.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>The input tensor of shape (batch_size, seq_length, d_model).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The output tensor of shape (batch_size, seq_length, vocab_size),           with log-softmax applied along the last dimension.</p> Source code in <code>src/rydberggpt/models/transformer/models.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Compute the forward pass of the Generator.\n\n    Args:\n        x (torch.Tensor): The input tensor of shape (batch_size, seq_length, d_model).\n\n    Returns:\n        (torch.Tensor): The output tensor of shape (batch_size, seq_length, vocab_size),\n                      with log-softmax applied along the last dimension.\n    \"\"\"\n\n    proj_offset = self.proj(x) + 1e-10\n    return F.log_softmax(proj_offset, dim=-1)  # [batch_size, seq_len, vocab_size]\n</code></pre>"},{"location":"reference/models/transformer/#rydberggpt.models.transformer.modules","title":"<code>modules</code>","text":""},{"location":"reference/models/transformer/#rydberggpt.models.transformer.modules.Embeddings","title":"<code>Embeddings</code>","text":"<p>               Bases: <code>Module</code></p> <p>The embedding layer.</p> <p>Parameters:</p> Name Type Description Default <code>d_model</code> <code>int</code> <p>The embedding size.</p> required <code>vocab_size</code> <code>int</code> <p>The vocabulary size.</p> required Source code in <code>src/rydberggpt/models/transformer/modules.py</code> <pre><code>class Embeddings(nn.Module):\n    \"\"\"\n    The embedding layer.\n\n    Args:\n        d_model (int): The embedding size.\n        vocab_size (int): The vocabulary size.\n    \"\"\"\n\n    def __init__(self, d_model: int, vocab_size: int):\n        super(Embeddings, self).__init__()\n        self.lut = nn.Linear(vocab_size, d_model)\n        self.d_model = d_model\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Compute the forward pass through the module.\n\n        Parameters:\n            x (torch.Tensor): The input tensor.\n\n        Returns:\n            (torch.Tensor): The output tensor.\n        \"\"\"\n        x = self.lut(x) * math.sqrt(self.d_model)\n        return x\n</code></pre>"},{"location":"reference/models/transformer/#rydberggpt.models.transformer.modules.Embeddings.forward","title":"<code>forward(x: torch.Tensor) -&gt; torch.Tensor</code>","text":"<p>Compute the forward pass through the module.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>The input tensor.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The output tensor.</p> Source code in <code>src/rydberggpt/models/transformer/modules.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Compute the forward pass through the module.\n\n    Parameters:\n        x (torch.Tensor): The input tensor.\n\n    Returns:\n        (torch.Tensor): The output tensor.\n    \"\"\"\n    x = self.lut(x) * math.sqrt(self.d_model)\n    return x\n</code></pre>"},{"location":"reference/models/transformer/#rydberggpt.models.transformer.modules.PositionalEncoding","title":"<code>PositionalEncoding</code>","text":"<p>               Bases: <code>Module</code></p> <p>Implement the PE function.</p> Source code in <code>src/rydberggpt/models/transformer/modules.py</code> <pre><code>class PositionalEncoding(nn.Module):\n    \"Implement the PE function.\"\n\n    def __init__(self, d_model, dropout, max_len=5000):\n        super(PositionalEncoding, self).__init__()\n        self.dropout = nn.Dropout(p=dropout)\n\n        # Compute the positional encodings once in log space.\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len).unsqueeze(1)\n        div_term = torch.exp(\n            torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n        )\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0)\n        self.register_buffer(\"pe\", pe)\n\n    def forward(self, x):\n        x = x + self.pe[:, : x.size(1)].requires_grad_(False)\n        return self.dropout(x)\n</code></pre>"},{"location":"reference/models/transformer/#rydberggpt.models.transformer.modules.PositionwiseFeedForward","title":"<code>PositionwiseFeedForward</code>","text":"<p>               Bases: <code>Module</code></p> <p>A two-layer feed-forward network.</p> <p>Parameters:</p> Name Type Description Default <code>d_model</code> <code>int</code> <p>The input size.</p> required <code>d_ff</code> <code>int</code> <p>The hidden size.</p> required <code>dropout</code> <code>float</code> <p>The dropout rate. Defaults to 0.1.</p> <code>0.1</code> Source code in <code>src/rydberggpt/models/transformer/modules.py</code> <pre><code>class PositionwiseFeedForward(nn.Module):\n    \"\"\"\n    A two-layer feed-forward network.\n\n    Args:\n        d_model (int): The input size.\n        d_ff (int): The hidden size.\n        dropout (float, optional): The dropout rate. Defaults to 0.1.\n    \"\"\"\n\n    def __init__(self, d_model: int, d_ff: int, dropout: float = 0.1):\n        super(PositionwiseFeedForward, self).__init__()\n        self.w_1 = nn.Linear(d_model, d_ff)\n        self.w_2 = nn.Linear(d_ff, d_model)\n        self.dropout = nn.Dropout(p=dropout)\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Compute the forward pass through the module.\n\n        Args:\n            x (torch.Tensor): The input tensor.\n\n        Returns:\n            (torch.Tensor): The output tensor.\n        \"\"\"\n        return self.w_2(self.dropout(F.relu(self.w_1(x))))\n</code></pre>"},{"location":"reference/models/transformer/#rydberggpt.models.transformer.modules.PositionwiseFeedForward.forward","title":"<code>forward(x: torch.Tensor) -&gt; torch.Tensor</code>","text":"<p>Compute the forward pass through the module.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>The input tensor.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The output tensor.</p> Source code in <code>src/rydberggpt/models/transformer/modules.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Compute the forward pass through the module.\n\n    Args:\n        x (torch.Tensor): The input tensor.\n\n    Returns:\n        (torch.Tensor): The output tensor.\n    \"\"\"\n    return self.w_2(self.dropout(F.relu(self.w_1(x))))\n</code></pre>"},{"location":"reference/models/transformer/#rydberggpt.models.transformer.modules.SublayerConnection","title":"<code>SublayerConnection</code>","text":"<p>               Bases: <code>Module</code></p> <p>This module implements a residual connection followed by a layer norm.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>int</code> <p>The input size.</p> required <code>dropout</code> <code>float</code> <p>The dropout rate.</p> required Source code in <code>src/rydberggpt/models/transformer/modules.py</code> <pre><code>class SublayerConnection(nn.Module):\n    \"\"\"\n    This module implements a residual connection followed by a layer norm.\n\n    Args:\n        size (int): The input size.\n        dropout (float): The dropout rate.\n    \"\"\"\n\n    def __init__(self, size: int, dropout: float):\n        super(SublayerConnection, self).__init__()\n        self.layer_norm = nn.LayerNorm(size)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x: torch.Tensor, sublayer: nn.Module) -&gt; torch.Tensor:\n        \"\"\"\n        Compute the forward pass through the module.\n\n        Args:\n            x (torch.Tensor): The input tensor.\n            sublayer (nn.Module): The sublayer module.\n\n        Returns:\n            (torch.Tensor): The output tensor.\n        \"\"\"\n        # NOTE For GPT2 the authors moved Layer normalization (Ba et al., 2016)\n        # to the input of each sub-block.\n        # see Sec. 2.3 https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf\n        return x + self.dropout(sublayer(self.layer_norm(x)))\n</code></pre>"},{"location":"reference/models/transformer/#rydberggpt.models.transformer.modules.SublayerConnection.forward","title":"<code>forward(x: torch.Tensor, sublayer: nn.Module) -&gt; torch.Tensor</code>","text":"<p>Compute the forward pass through the module.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>The input tensor.</p> required <code>sublayer</code> <code>Module</code> <p>The sublayer module.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The output tensor.</p> Source code in <code>src/rydberggpt/models/transformer/modules.py</code> <pre><code>def forward(self, x: torch.Tensor, sublayer: nn.Module) -&gt; torch.Tensor:\n    \"\"\"\n    Compute the forward pass through the module.\n\n    Args:\n        x (torch.Tensor): The input tensor.\n        sublayer (nn.Module): The sublayer module.\n\n    Returns:\n        (torch.Tensor): The output tensor.\n    \"\"\"\n    # NOTE For GPT2 the authors moved Layer normalization (Ba et al., 2016)\n    # to the input of each sub-block.\n    # see Sec. 2.3 https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf\n    return x + self.dropout(sublayer(self.layer_norm(x)))\n</code></pre>"},{"location":"reference/models/transformer/#rydberggpt.models.transformer.utils","title":"<code>utils</code>","text":""},{"location":"reference/models/transformer/#rydberggpt.models.transformer.utils.clones","title":"<code>clones(module: nn.Module, n_clones: int)</code>","text":"<p>helper function which produces n_clones copies of a layer</p> Source code in <code>src/rydberggpt/models/transformer/utils.py</code> <pre><code>def clones(module: nn.Module, n_clones: int):\n    \"\"\"helper function which produces n_clones copies of a layer\"\"\"\n    return nn.ModuleList([copy.deepcopy(module) for _ in range(n_clones)])\n</code></pre>"},{"location":"reference/models/transformer/#rydberggpt.models.transformer.utils.flattened_snake_flip","title":"<code>flattened_snake_flip(x: torch.Tensor, Lx: int, Ly: int) -&gt; torch.Tensor</code>","text":"<p>Implements a \"snake\" flip which reorders the flattened 2D tensor into snake order.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>The tensor to apply the snake flip to, dimensions should be [..., Ly * Lx].</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The \"snake\" flipped tensor, dimensions will be [..., Ly * Lx].</p> Source code in <code>src/rydberggpt/models/transformer/utils.py</code> <pre><code>def flattened_snake_flip(x: torch.Tensor, Lx: int, Ly: int) -&gt; torch.Tensor:\n    \"\"\"\n    Implements a \"snake\" flip which reorders the flattened 2D tensor into snake order.\n\n    Args:\n        x (torch.Tensor): The tensor to apply the snake flip to, dimensions should be [..., Ly * Lx].\n\n    Returns:\n        (torch.Tensor): The \"snake\" flipped tensor, dimensions will be [..., Ly * Lx].\n    \"\"\"\n    return snake_flip(x.reshape(*x.shape[:-1], Ly, Lx)).reshape(*x.shape[:-1], -1)\n</code></pre>"},{"location":"reference/models/transformer/#rydberggpt.models.transformer.utils.snake_flip","title":"<code>snake_flip(x: torch.Tensor) -&gt; torch.Tensor</code>","text":"<p>Implements a \"snake\" flip which reorders the 2D tensor into snake order when flattened.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>The tensor to apply the snake flip to, dimensions should be [..., Ly, Lx].</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The \"snake\" flipped tensor, dimensions will be [..., Ly, Lx].</p> Source code in <code>src/rydberggpt/models/transformer/utils.py</code> <pre><code>def snake_flip(x: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Implements a \"snake\" flip which reorders the 2D tensor into snake order when flattened.\n\n    Args:\n        x (torch.Tensor): The tensor to apply the snake flip to, dimensions should be [..., Ly, Lx].\n\n    Returns:\n        (torch.Tensor): The \"snake\" flipped tensor, dimensions will be [..., Ly, Lx].\n    \"\"\"\n\n    if not isinstance(x, torch.Tensor):\n        raise TypeError(\"Function only supports torch.Tensor\")\n\n    y = x.clone()\n\n    for i in range(y.shape[-2]):\n        if i % 2 == 1:\n            y[..., i, :] = torch.flip(y[..., i, :], dims=(-1,))\n\n    return y\n</code></pre>"}]}