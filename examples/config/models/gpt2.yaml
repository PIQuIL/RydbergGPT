transformer:
  num_heads: 8
  d_model: 128
  num_blocks: 8
  d_ff: 512 # usually 4 * d_model
  dropout: 0.1

training:
  num_epochs: 10
  batch_size: 64
  learning_rate: 0.01

dataset:
  num_atoms: null
  num_samples: null
  delta: null

rydberg:
  num_states: 2
  num_encoder_embedding_dims: 4

misc:
  device: null
  profiling: True
  seed: 42
  prog_bar: False